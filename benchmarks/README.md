# QuantForge ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

é«˜æ€§èƒ½ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªQuantForgeã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šãƒ»ç®¡ç†ã™ã‚‹Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚

## ğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹æˆ

```
benchmarks/                      # Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â”œâ”€â”€ __init__.py                  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åˆæœŸåŒ–
â”œâ”€â”€ __main__.py                  # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ common/                      # å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                  # BenchmarkBaseåŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ formatters.py            # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
â”‚   â”œâ”€â”€ io.py                    # ãƒ•ã‚¡ã‚¤ãƒ«I/Oç®¡ç†
â”‚   â””â”€â”€ metrics.py               # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
â”œâ”€â”€ baseline/                    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ python_baseline.py      # Pure Pythonå®Ÿè£…
â”‚   â”œâ”€â”€ iv_baseline.py           # SciPyå®Ÿè£…
â”‚   â””â”€â”€ iv_vectorized.py         # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Ÿè£…
â”œâ”€â”€ runners/                     # å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ comparison.py            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œï¼ˆæ—§å®Ÿè£…ï¼‰
â”‚   â”œâ”€â”€ comparison_refactored.py # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œï¼ˆæ–°å®Ÿè£…ï¼‰
â”‚   â”œâ”€â”€ practical.py             # å®Ÿè·µã‚·ãƒŠãƒªã‚ª
â”‚   â””â”€â”€ arraylike.py             # ArrayLikeãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ analysis/                    # åˆ†æãƒ„ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ save.py                  # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†
â”‚   â”œâ”€â”€ analyze.py               # åˆ†æãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
â”‚   â””â”€â”€ format.py                # Markdownç”Ÿæˆ
â””â”€â”€ results/                     # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆçœŸå®Ÿã®æºï¼‰
    â”œâ”€â”€ history.jsonl            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆè¿½è¨˜å‹ï¼‰
    â”œâ”€â”€ latest.json              # æœ€æ–°çµæœ
    â””â”€â”€ history.csv              # åˆ†æç”¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
```bash
# ã©ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã§ã‚‚å®Ÿè¡Œå¯èƒ½
python -m benchmarks                        # ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º
python -m benchmarks.runners.comparison     # æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
python -m benchmarks.runners.practical      # å®Ÿè·µã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
python -m benchmarks.analysis.analyze       # çµæœåˆ†æ
python -m benchmarks.analysis.format        # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```

### æ—§æ¥ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
```bash
cd benchmarks
./run_benchmarks.sh  # çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã¾ã åˆ©ç”¨å¯èƒ½ï¼‰
```

## ğŸ“Š æ¸¬å®šå†…å®¹

### 1. å˜ä¸€è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- QuantForge (Rust + PyO3)
- Pure Python (mathãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿)
- SciPy (scipy.stats.normä½¿ç”¨)

### 2. ãƒãƒƒãƒå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- QuantForge ãƒãƒƒãƒAPI
- NumPy ãƒ™ã‚¯ãƒˆãƒ«åŒ–
- Pure Python ãƒ«ãƒ¼ãƒ—ï¼ˆå°è¦æ¨¡ã®ã¿ï¼‰

### 3. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§
- 100, 1,000, 10,000, 100,000, 1,000,000 è¦ç´ 
- FFIã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®æ¸¬å®š
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆé£½å’Œç‚¹ã®ç‰¹å®š

## ğŸ”§ å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨

### BenchmarkBase ã‚¯ãƒ©ã‚¹
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè£…ã®åŸºåº•ã‚¯ãƒ©ã‚¹ã§ã€æ™‚é–“æ¸¬å®šã‚„ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—ãªã©ã®å…±é€šæ©Ÿèƒ½ã‚’æä¾›ï¼š

```python
from benchmarks.common import BenchmarkBase
from typing import Any

class MyBenchmark(BenchmarkBase):
    def __init__(self):
        super().__init__(warmup_runs=100, measure_runs=1000)
    
    def run(self) -> dict[str, Any]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ."""
        self.start_benchmark()
        
        # time_functionãƒ¡ã‚½ãƒƒãƒ‰ã§è‡ªå‹•æ¸¬å®š
        timing = self.time_function(lambda: some_function())
        
        return {
            "system_info": self.get_system_info(),
            "result": timing.median  # TimingResultã‹ã‚‰ä¸­å¤®å€¤ã‚’å–å¾—
        }
```

### TimingResult ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
æ¸¬å®šçµæœã‚’æ ¼ç´ã™ã‚‹æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼š

```python
from benchmarks.common.base import TimingResult

# è‡ªå‹•çš„ã«çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
timing = TimingResult.from_times([0.001, 0.002, 0.0015])
print(f"ä¸­å¤®å€¤: {timing.median}ç§’")
print(f"å¹³å‡: {timing.mean}ç§’, æ¨™æº–åå·®: {timing.std}ç§’")
```

### BenchmarkFormatter
çµæœã‚’Markdownå½¢å¼ã§æ•´å½¢ï¼š

```python
from benchmarks.common import BenchmarkFormatter

formatter = BenchmarkFormatter("My Benchmark Results")
markdown = formatter.format_markdown(results)
print(markdown)  # ç¾ã—ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸMarkdownå‡ºåŠ›
```

### BenchmarkIO
çµæœã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ãƒ»æ¯”è¼ƒï¼š

```python
from benchmarks.common import BenchmarkIO

io = BenchmarkIO()
io.save_result(results)  # è‡ªå‹•çš„ã«history.jsonlã«è¿½è¨˜
latest = io.load_latest()  # æœ€æ–°çµæœã‚’èª­ã¿è¾¼ã¿
comparison = io.compare_results()  # å‰å›ã¨ã®æ¯”è¼ƒ
```

## ğŸ“ˆ åˆ†ææ©Ÿèƒ½

### Pythonã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®ä½¿ç”¨
```python
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from benchmarks.baseline.python_baseline import (
    black_scholes_pure_python,
    black_scholes_numpy_batch
)

# åˆ†æãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from benchmarks.analysis.analyze import (
    detect_performance_trends,
    generate_summary_table
)
from benchmarks.analysis.save import save_benchmark_result

# å®Ÿè¡Œä¾‹ï¼ˆæ—§ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
result = black_scholes_pure_python(s=100, k=105, t=1.0, r=0.05, sigma=0.2)
print(f"Pure Python Result: {result:.4f}")

# åˆ†æã®å®Ÿè¡Œ
trends = detect_performance_trends()
summary = generate_summary_table()

# æ–°ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰
from benchmarks.common import BenchmarkBase, BenchmarkIO, BenchmarkFormatter

class QuickTest(BenchmarkBase):
    def run(self):
        timing = self.time_function(
            lambda: black_scholes_pure_python(100, 105, 1.0, 0.05, 0.2)
        )
        return {"pure_python": timing.median}

test = QuickTest()
results = test.run()
print(f"å®Ÿè¡Œæ™‚é–“: {results['pure_python']*1e6:.2f} Î¼s")
```

## ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

### JSON Lines (history.jsonl)
å„è¡ŒãŒç‹¬ç«‹ã—ãŸJSONï¼š
```json
{"timestamp": "2025-08-27T14:41:14", "system_info": {...}, "single": {...}, "batch": [...]}
```

### Latest JSON (latest.json)
æœ€æ–°çµæœã®å®Œå…¨ãªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆæ•´å½¢æ¸ˆã¿ï¼‰

### CSV (history.csv)
| ã‚«ãƒ©ãƒ  | èª¬æ˜ |
|--------|------|
| timestamp | ISO 8601å½¢å¼ |
| cpu | ãƒ—ãƒ­ã‚»ãƒƒã‚µå |
| cpu_count | ç‰©ç†ã‚³ã‚¢æ•° |
| memory_gb | ãƒ¡ãƒ¢ãƒªå®¹é‡ |
| single_quantforge_us | å˜ä¸€è¨ˆç®—æ™‚é–“ï¼ˆÎ¼sï¼‰ |
| batch_1m_quantforge_ms | 100ä¸‡ä»¶å‡¦ç†æ™‚é–“ï¼ˆmsï¼‰ |
| throughput_mops | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆM ops/secï¼‰ |

## âš ï¸ æ³¨æ„äº‹é …

### ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§
- `history.jsonl`ã¯è¿½è¨˜å°‚ç”¨ï¼ˆç·¨é›†ã—ãªã„ï¼‰
- æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„
- ãƒ‘ã‚¹ã¯å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¾å­˜ã—ãªã„è¨­è¨ˆï¼ˆ`Path(__file__).resolve()`ä½¿ç”¨ï¼‰

### æ¸¬å®šã®å†ç¾æ€§
- åŒä¸€ç’°å¢ƒã§ã®æ¸¬å®šã‚’æ¨å¥¨
- ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒä½ã„çŠ¶æ…‹ã§å®Ÿè¡Œ
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œå¾Œã«æ¸¬å®šï¼ˆè‡ªå‹•å®Ÿæ–½ï¼‰

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ImportError: psutil
```bash
uv add psutil
```

### ImportError: types-psutil
```bash
uv add --dev types-psutil
```

### æ¨©é™ã‚¨ãƒ©ãƒ¼ï¼ˆrun_benchmarks.shï¼‰
```bash
chmod +x run_benchmarks.sh
```

## ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

åŒ…æ‹¬çš„ãªç®¡ç†æ–¹æ³•ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã‚’å‚ç…§ï¼š

â†’ **[ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç®¡ç†ã‚¬ã‚¤ãƒ‰](../docs/ja/internal/benchmark_management_guide.md)**

ãã®ä»–ã®é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼š
- [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ](../docs/performance/benchmarks.md)
- [æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰](../docs/performance/optimization.md)