# QuantForge ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

é«˜æ€§èƒ½ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªQuantForgeã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šãƒ»ç®¡ç†ã™ã‚‹Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚

## ğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹æˆ

```
benchmarks/                      # Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â”œâ”€â”€ __init__.py                  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åˆæœŸåŒ–
â”œâ”€â”€ __main__.py                  # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ baseline/                    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ python_baseline.py      # Pure Pythonå®Ÿè£…
â”‚   â”œâ”€â”€ iv_baseline.py           # SciPyå®Ÿè£…
â”‚   â””â”€â”€ iv_vectorized.py         # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Ÿè£…
â”œâ”€â”€ runners/                     # å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ comparison.py            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
â”‚   â”œâ”€â”€ practical.py             # å®Ÿè·µã‚·ãƒŠãƒªã‚ª
â”‚   â””â”€â”€ arraylike.py             # ArrayLikeãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ analysis/                    # åˆ†æãƒ„ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ save.py                  # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†
â”‚   â”œâ”€â”€ analyze.py               # åˆ†æãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
â”‚   â””â”€â”€ format.py                # Markdownç”Ÿæˆ
â””â”€â”€ results/                     # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆçœŸå®Ÿã®æºï¼‰
    â”œâ”€â”€ history.jsonl            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆè¿½è¨˜å‹ï¼‰
    â”œâ”€â”€ latest.json              # æœ€æ–°çµæœ
    â””â”€â”€ history.csv              # åˆ†æç”¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
```bash
# ã©ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã§ã‚‚å®Ÿè¡Œå¯èƒ½
python -m benchmarks                        # ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º
python -m benchmarks.runners.comparison     # æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
python -m benchmarks.runners.practical      # å®Ÿè·µã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
python -m benchmarks.analysis.analyze       # çµæœåˆ†æ
python -m benchmarks.analysis.format        # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```

### æ—§æ¥ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
```bash
cd benchmarks
./run_benchmarks.sh  # çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã¾ã åˆ©ç”¨å¯èƒ½ï¼‰
```

## ğŸ“Š æ¸¬å®šå†…å®¹

### 1. å˜ä¸€è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- QuantForge (Rust + PyO3)
- Pure Python (mathãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿)
- SciPy (scipy.stats.normä½¿ç”¨)

### 2. ãƒãƒƒãƒå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- QuantForge ãƒãƒƒãƒAPI
- NumPy ãƒ™ã‚¯ãƒˆãƒ«åŒ–
- Pure Python ãƒ«ãƒ¼ãƒ—ï¼ˆå°è¦æ¨¡ã®ã¿ï¼‰

### 3. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§
- 100, 1,000, 10,000, 100,000, 1,000,000 è¦ç´ 
- FFIã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®æ¸¬å®š
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆé£½å’Œç‚¹ã®ç‰¹å®š

## ğŸ“ˆ åˆ†ææ©Ÿèƒ½

### Pythonã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®ä½¿ç”¨
```python
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from benchmarks.baseline.python_baseline import (
    black_scholes_pure_python,
    black_scholes_numpy_batch
)

# åˆ†æãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from benchmarks.analysis.analyze import (
    detect_performance_trends,
    generate_summary_table
)
from benchmarks.analysis.save import save_benchmark_result

# å®Ÿè¡Œä¾‹
result = black_scholes_pure_python(s=100, k=105, t=1.0, r=0.05, sigma=0.2)
print(f"Pure Python Result: {result:.4f}")

# åˆ†æã®å®Ÿè¡Œ
trends = detect_performance_trends()
summary = generate_summary_table()
```

## ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

### JSON Lines (history.jsonl)
å„è¡ŒãŒç‹¬ç«‹ã—ãŸJSONï¼š
```json
{"timestamp": "2025-08-27T14:41:14", "system_info": {...}, "single": {...}, "batch": [...]}
```

### Latest JSON (latest.json)
æœ€æ–°çµæœã®å®Œå…¨ãªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆæ•´å½¢æ¸ˆã¿ï¼‰

### CSV (history.csv)
| ã‚«ãƒ©ãƒ  | èª¬æ˜ |
|--------|------|
| timestamp | ISO 8601å½¢å¼ |
| cpu | ãƒ—ãƒ­ã‚»ãƒƒã‚µå |
| cpu_count | ç‰©ç†ã‚³ã‚¢æ•° |
| memory_gb | ãƒ¡ãƒ¢ãƒªå®¹é‡ |
| single_quantforge_us | å˜ä¸€è¨ˆç®—æ™‚é–“ï¼ˆÎ¼sï¼‰ |
| batch_1m_quantforge_ms | 100ä¸‡ä»¶å‡¦ç†æ™‚é–“ï¼ˆmsï¼‰ |
| throughput_mops | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆM ops/secï¼‰ |

## âš ï¸ æ³¨æ„äº‹é …

### ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§
- `history.jsonl`ã¯è¿½è¨˜å°‚ç”¨ï¼ˆç·¨é›†ã—ãªã„ï¼‰
- æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„
- ãƒ‘ã‚¹ã¯å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¾å­˜ã—ãªã„è¨­è¨ˆï¼ˆ`Path(__file__).resolve()`ä½¿ç”¨ï¼‰

### æ¸¬å®šã®å†ç¾æ€§
- åŒä¸€ç’°å¢ƒã§ã®æ¸¬å®šã‚’æ¨å¥¨
- ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒä½ã„çŠ¶æ…‹ã§å®Ÿè¡Œ
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œå¾Œã«æ¸¬å®šï¼ˆè‡ªå‹•å®Ÿæ–½ï¼‰

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ImportError: psutil
```bash
uv add psutil
```

### ImportError: types-psutil
```bash
uv add --dev types-psutil
```

### æ¨©é™ã‚¨ãƒ©ãƒ¼ï¼ˆrun_benchmarks.shï¼‰
```bash
chmod +x run_benchmarks.sh
```

## ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

åŒ…æ‹¬çš„ãªç®¡ç†æ–¹æ³•ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã‚’å‚ç…§ï¼š

â†’ **[ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç®¡ç†ã‚¬ã‚¤ãƒ‰](../docs/ja/internal/benchmark_management_guide.md)**

ãã®ä»–ã®é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼š
- [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ](../docs/performance/benchmarks.md)
- [æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰](../docs/performance/optimization.md)