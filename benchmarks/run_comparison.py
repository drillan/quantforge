"""Black-Scholesã®æ€§èƒ½æ¯”è¼ƒ."""

import json
import platform
import time
from typing import Any

import numpy as np
import psutil
from python_baseline import (
    black_scholes_numpy_batch,
    black_scholes_pure_python,
    black_scholes_pure_python_batch,
    black_scholes_scipy_single,
)
from quantforge.models import black_scholes


class BenchmarkRunner:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¯ãƒ©ã‚¹."""

    def __init__(self, warmup_runs: int = 100, measure_runs: int = 1000):
        self.warmup_runs = warmup_runs
        self.measure_runs = measure_runs

    def get_system_info(self) -> dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—."""
        return {
            "platform": platform.platform(),
            "processor": platform.processor(),
            "cpu_count": psutil.cpu_count(logical=False),
            "cpu_count_logical": psutil.cpu_count(logical=True),
            "memory_gb": round(psutil.virtual_memory().total / (1024**3), 1),
            "python_version": platform.python_version(),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }

    def benchmark_single(self) -> dict[str, Any]:
        """å˜ä¸€è¨ˆç®—ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯."""
        s, k, t, r, sigma = 100.0, 100.0, 1.0, 0.05, 0.2

        results: dict[str, Any] = {}

        # QuantForge (Rust)
        for _ in range(self.warmup_runs):
            black_scholes.call_price(s, k, t, r, sigma)

        times = []
        for _ in range(self.measure_runs):
            start = time.perf_counter()
            black_scholes.call_price(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        qf_time = np.median(times)  # ä¸­å¤®å€¤ã‚’ä½¿ç”¨ï¼ˆå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›ï¼‰
        results["quantforge"] = qf_time

        # Pure Pythonï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼‰
        for _ in range(min(self.warmup_runs, 10)):  # é…ã„ã®ã§å°‘ãªã‚
            black_scholes_pure_python(s, k, t, r, sigma)

        times = []
        for _ in range(min(self.measure_runs, 100)):  # é…ã„ã®ã§å°‘ãªã‚
            start = time.perf_counter()
            black_scholes_pure_python(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        py_time = np.median(times)
        results["pure_python"] = py_time

        # SciPyï¼ˆä¸€èˆ¬çš„ãªå®Ÿè£…ï¼‰
        for _ in range(self.warmup_runs):
            black_scholes_scipy_single(s, k, t, r, sigma)

        times = []
        for _ in range(self.measure_runs):
            start = time.perf_counter()
            black_scholes_scipy_single(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        scipy_time = np.median(times)
        results["scipy"] = scipy_time

        # ç›¸å¯¾æ€§èƒ½è¨ˆç®—
        results["speedup_vs_pure_python"] = py_time / qf_time
        results["speedup_vs_scipy"] = scipy_time / qf_time

        return results

    def benchmark_batch(self, size: int) -> dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯."""
        spots = np.random.uniform(50, 150, size).astype(np.float64)
        spots_list = spots.tolist()  # Pure Pythonç”¨
        k, t, r, sigma = 100.0, 1.0, 0.05, 0.2

        results: dict[str, Any] = {"size": size}

        # QuantForge
        _ = black_scholes.call_price_batch(spots[: min(100, size)], k, t, r, sigma)
        start = time.perf_counter()
        _ = black_scholes.call_price_batch(spots, k, t, r, sigma)
        qf_time = time.perf_counter() - start
        results["quantforge"] = qf_time

        # NumPy Batch
        _ = black_scholes_numpy_batch(spots[: min(100, size)], k, t, r, sigma)
        start = time.perf_counter()
        _ = black_scholes_numpy_batch(spots, k, t, r, sigma)
        np_time = time.perf_counter() - start
        results["numpy_batch"] = np_time

        # Pure Python (å°ã•ã„ã‚µã‚¤ã‚ºã®ã¿)
        if size <= 1000:
            start = time.perf_counter()
            _ = black_scholes_pure_python_batch(spots_list, k, t, r, sigma)
            py_time = time.perf_counter() - start
            results["pure_python"] = py_time
            results["speedup_vs_pure_python"] = py_time / qf_time

        # ç›¸å¯¾æ€§èƒ½ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        results["speedup_vs_numpy"] = np_time / qf_time
        results["throughput_qf"] = size / qf_time
        results["throughput_np"] = size / np_time

        return results

    def run_all(self) -> dict[str, Any]:
        """å…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ."""
        print("ğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")

        results: dict[str, Any] = {"system_info": self.get_system_info(), "single": {}, "batch": []}

        print("ğŸ“Š å˜ä¸€è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
        results["single"] = self.benchmark_single()

        print("ğŸ“Š ãƒãƒƒãƒå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
        for size in [100, 1000, 10000, 100000, 1000000]:
            print(f"  - ã‚µã‚¤ã‚º {size:,} ...")
            results["batch"].append(self.benchmark_batch(size))

        # çµæœã‚’æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
        from save_results import save_benchmark_result
        save_benchmark_result(results)
        
        # äº’æ›æ€§ã®ãŸã‚å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜
        with open("benchmark_results.json", "w") as f:
            json.dump(results, f, indent=2)

        print("âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        return results


if __name__ == "__main__":
    runner = BenchmarkRunner()
    results = runner.run_all()

    # ç°¡æ˜“çµæœè¡¨ç¤º
    print("\n=== çµæœã‚µãƒãƒª ===")
    single = results["single"]
    print(f"å˜ä¸€è¨ˆç®—: QuantForgeã¯Pure Pythonã‚ˆã‚Š{single['speedup_vs_pure_python']:.0f}å€é«˜é€Ÿ")

    batch_1m = next((b for b in results["batch"] if b["size"] == 1000000), None)
    if batch_1m:
        print(f"100ä¸‡ä»¶ãƒãƒƒãƒ: QuantForgeã¯NumPyã‚ˆã‚Š{batch_1m['speedup_vs_numpy']:.1f}å€é«˜é€Ÿ")
        print(f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {batch_1m['throughput_qf'] / 1e6:.1f}M ops/sec")
