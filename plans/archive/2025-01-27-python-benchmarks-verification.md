# [Python] Black-Scholesãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å†æ¤œè¨¼ å®Ÿè£…è¨ˆç”»

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
- **ä½œæˆæ—¥**: 2025-01-27
- **è¨€èª**: Python
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: COMPLETED
- **æ¨å®šè¦æ¨¡**: ä¸­
- **æ¨å®šã‚³ãƒ¼ãƒ‰è¡Œæ•°**: 300-400è¡Œ
- **å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**: benchmarks/, scripts/, docs/performance/

## âš ï¸ æŠ€è¡“çš„è² å‚µã‚¼ãƒ­ã®åŸå‰‡

**é‡è¦**: ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯æŠ€è¡“çš„è² å‚µã‚’ä¸€åˆ‡ä½œã‚‰ãªã„ã“ã¨ã‚’æœ€å„ªå…ˆã¨ã—ã¾ã™ã€‚

### ç¦æ­¢äº‹é …ï¼ˆã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
âŒ **æ®µéšçš„å®Ÿè£…ãƒ»TODOæ®‹ã—**
```python
# çµ¶å¯¾ã«ãƒ€ãƒ¡ãªä¾‹
def measure_performance():
    # TODO: å¾Œã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚‚è¿½åŠ 
    return black_scholes_only()  # æš«å®šå®Ÿè£…
```

âŒ **ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç’°å¢ƒæƒ…å ±**
```python
# çµ¶å¯¾ã«ãƒ€ãƒ¡ãªä¾‹
CPU_NAME = "Intel Core i9-12900K"  # ç‰¹å®šç’°å¢ƒã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
PERFORMANCE_NS = 8  # ç†è«–å€¤ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
```

âœ… **æ­£ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šå®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹ã®å®Œå…¨å®Ÿè£…**
```python
# å®Ÿéš›ã®ç’°å¢ƒã§æ¸¬å®šã—ãŸå€¤ã®ã¿ã‚’ä½¿ç”¨
import platform
import psutil

def get_system_info():
    """å®Ÿè¡Œç’°å¢ƒã®æƒ…å ±ã‚’å–å¾—."""
    return {
        "cpu": platform.processor(),
        "cpu_count": psutil.cpu_count(),
        "memory": psutil.virtual_memory().total,
    }

def measure_actual_performance():
    """å®Ÿéš›ã®æ¸¬å®šå€¤ã‚’è¿”ã™."""
    return time_function(black_scholes.call_price, ...)
```

## ã‚¿ã‚¹ã‚¯è¦æ¨¡åˆ¤å®š

### åˆ¤å®šåŸºæº–
- [x] æ¨å®šã‚³ãƒ¼ãƒ‰è¡Œæ•°: 300-400è¡Œ
- [x] æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 4å€‹
- [x] å½±éŸ¿ç¯„å›²: è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆbenchmarks/, scripts/, docs/ï¼‰
- [x] Rusté€£æº: å¿…è¦ï¼ˆæ—¢å­˜ã®Black-Scholesãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
- [x] NumPy/Pandasä½¿ç”¨: ã‚ã‚Šï¼ˆNumPyç‰ˆã¨SciPyç‰ˆã®æ¯”è¼ƒå®Ÿè£…ï¼‰
- [ ] éåŒæœŸå‡¦ç†: ä¸è¦

### è¦æ¨¡åˆ¤å®šçµæœ
**ä¸­è¦æ¨¡ã‚¿ã‚¹ã‚¯**

## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```
benchmarks/
â”œâ”€â”€ python_baseline.py        # Pure Python, SciPy, NumPyå®Ÿè£…
â”œâ”€â”€ run_comparison.py         # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ format_results.py         # çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
â””â”€â”€ run_benchmarks.sh         # çµ±åˆå®Ÿè¡Œã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆè‡ªå·±å®Œçµçš„é…ç½®ï¼‰
```

**è¨­è¨ˆæ ¹æ‹ **: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’`benchmarks/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é›†ç´„ã™ã‚‹ã“ã¨ã§ã€é«˜ã„å‡é›†æ€§ã¨ç™ºè¦‹å®¹æ˜“æ€§ã‚’å®Ÿç¾ã€‚`scripts/`ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ç®¡ç†ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã•ã›ã‚‹ã€‚

## ç›®çš„ã¨èƒŒæ™¯

### ç¾åœ¨ã®å•é¡Œç‚¹
1. **ä¸æ­£ç¢ºãªæ¸¬å®šç’°å¢ƒ**
   - ãƒã‚¤ã‚¨ãƒ³ãƒ‰CPUã§ã®ç†è«–å€¤ï¼ˆ8nsï¼‰ãŒè¨˜è¼‰
   - å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒã¨ä¹–é›¢
   - å†ç¾æ€§ãŒãªã„

2. **å…¬æ­£æ€§ã®æ¬ å¦‚**
   - æœ€è‰¯æ¡ä»¶ã®ã¿ã®è¨˜è¼‰
   - æ¸¬å®šæ–¹æ³•ãŒä¸é€æ˜
   - æ¯”è¼ƒåŸºæº–ãŒä¸æ˜ç¢º

### è§£æ±ºæ–¹é‡
1. **å®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹**
   - å®Ÿéš›ã®ç’°å¢ƒã§ã®æ¸¬å®š
   - è¤‡æ•°å›æ¸¬å®šã®çµ±è¨ˆå€¤ä½¿ç”¨
   - ç’°å¢ƒæƒ…å ±ã®æ˜è¨˜

2. **ç›¸å¯¾æ€§èƒ½é‡è¦–**
   - Pure Pythonå®Ÿè£…ã¨ã®æ¯”è¼ƒï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼‰
   - SciPyå®Ÿè£…ã¨ã®æ¯”è¼ƒï¼ˆä¸€èˆ¬çš„ãªå®Ÿè£…ï¼‰
   - NumPyå®Ÿè£…ã¨ã®æ¯”è¼ƒï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
   - çµ¶å¯¾å€¤ã‚ˆã‚Šå€ç‡ã‚’é‡è¦–

3. **å†ç¾å¯èƒ½æ€§**
   - æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æä¾›
   - è©³ç´°ãªæ¸¬å®šæ–¹æ³•ã®æ–‡æ›¸åŒ–
   - Dockerç’°å¢ƒã¯åˆ¥è¨ˆç”»ã§å¯¾å¿œ

## å®Ÿè£…è¨ˆç”»

### Phase 1: è¨­è¨ˆï¼ˆ1æ™‚é–“ï¼‰
- [x] ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ§‹æˆã®è¨­è¨ˆ
- [x] æ¸¬å®šé …ç›®ã®é¸å®šï¼ˆBlack-Scholesã®ã¿ï¼‰
- [x] å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ±ºå®š

### Phase 2: å®Ÿè£…ï¼ˆ4æ™‚é–“ï¼‰

#### 2.1 Pythonæ¯”è¼ƒå®Ÿè£…ï¼ˆbenchmarks/python_baseline.pyï¼‰
```python
"""Black-Scholesã®å„ç¨®Pythonå®Ÿè£…."""

import math
import numpy as np
from scipy.stats import norm
from typing import Union, List
from numpy.typing import NDArray

def erf_approx(x: float) -> float:
    """èª¤å·®é–¢æ•°ã®è¿‘ä¼¼è¨ˆç®—ï¼ˆAbramowitz and Stegunè¿‘ä¼¼ï¼‰."""
    # Pure Pythonç”¨ã®ç´¯ç©æ­£è¦åˆ†å¸ƒé–¢æ•°ã®å®Ÿè£…
    # erfã®å¤šé …å¼è¿‘ä¼¼ã‚’ä½¿ç”¨
    a1 =  0.254829592
    a2 = -0.284496736
    a3 =  1.421413741
    a4 = -1.453152027
    a5 =  1.061405429
    p  =  0.3275911
    
    sign = 1 if x >= 0 else -1
    x = abs(x)
    
    t = 1.0 / (1.0 + p * x)
    t2 = t * t
    t3 = t2 * t
    t4 = t3 * t
    t5 = t4 * t
    y = 1.0 - ((((a5 * t5 + a4 * t4) + a3 * t3) + a2 * t2) + a1 * t) * math.exp(-x * x)
    
    return sign * y

def norm_cdf_pure(x: float) -> float:
    """ç´¯ç©æ­£è¦åˆ†å¸ƒé–¢æ•°ï¼ˆPure Pythonå®Ÿè£…ï¼‰."""
    return 0.5 * (1.0 + erf_approx(x / math.sqrt(2.0)))

def black_scholes_pure_python(
    s: float, k: float, t: float, r: float, sigma: float
) -> float:
    """ç´”Pythonå®Ÿè£…ï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼‰."""
    # mathãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ä½¿ç”¨
    sqrt_t = math.sqrt(t)
    d1 = (math.log(s / k) + (r + 0.5 * sigma * sigma) * t) / (sigma * sqrt_t)
    d2 = d1 - sigma * sqrt_t
    
    # ç´¯ç©æ­£è¦åˆ†å¸ƒé–¢æ•°ã‚’è‡ªå‰å®Ÿè£…
    nd1 = norm_cdf_pure(d1)
    nd2 = norm_cdf_pure(d2)
    
    return s * nd1 - k * math.exp(-r * t) * nd2

def black_scholes_scipy_single(
    s: float, k: float, t: float, r: float, sigma: float
) -> float:
    """SciPyå®Ÿè£…ï¼ˆä¸€èˆ¬çš„ãªå®Ÿè£…ï¼‰."""
    d1 = (np.log(s / k) + (r + 0.5 * sigma ** 2) * t) / (sigma * np.sqrt(t))
    d2 = d1 - sigma * np.sqrt(t)
    return s * norm.cdf(d1) - k * np.exp(-r * t) * norm.cdf(d2)

def black_scholes_numpy_batch(
    spots: NDArray[np.float64],
    k: float, t: float, r: float, sigma: float
) -> NDArray[np.float64]:
    """NumPyå®Ÿè£…ï¼ˆãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–ï¼‰."""
    sqrt_t = np.sqrt(t)
    d1 = (np.log(spots / k) + (r + 0.5 * sigma ** 2) * t) / (sigma * sqrt_t)
    d2 = d1 - sigma * sqrt_t
    return spots * norm.cdf(d1) - k * np.exp(-r * t) * norm.cdf(d2)

def black_scholes_pure_python_batch(
    spots: List[float],
    k: float, t: float, r: float, sigma: float
) -> List[float]:
    """Pure Pythonãƒãƒƒãƒå‡¦ç†ï¼ˆãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ï¼‰."""
    return [black_scholes_pure_python(s, k, t, r, sigma) for s in spots]
```

#### 2.2 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆbenchmarks/run_comparison.pyï¼‰
```python
"""Black-Scholesã®æ€§èƒ½æ¯”è¼ƒ."""

import time
import json
import numpy as np
import platform
import psutil
from typing import Dict, Any, List
from quantforge.models import black_scholes
from python_baseline import (
    black_scholes_pure_python,
    black_scholes_scipy_single,
    black_scholes_numpy_batch,
    black_scholes_pure_python_batch
)

class BenchmarkRunner:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¯ãƒ©ã‚¹."""
    
    def __init__(self, warmup_runs: int = 100, measure_runs: int = 1000):
        self.warmup_runs = warmup_runs
        self.measure_runs = measure_runs
        
    def get_system_info(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—."""
        return {
            "platform": platform.platform(),
            "processor": platform.processor(),
            "cpu_count": psutil.cpu_count(logical=False),
            "cpu_count_logical": psutil.cpu_count(logical=True),
            "memory_gb": round(psutil.virtual_memory().total / (1024**3), 1),
            "python_version": platform.python_version(),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
    
    def benchmark_single(self) -> Dict[str, float]:
        """å˜ä¸€è¨ˆç®—ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯."""
        s, k, t, r, sigma = 100.0, 100.0, 1.0, 0.05, 0.2
        
        results = {}
        
        # QuantForge (Rust)
        for _ in range(self.warmup_runs):
            black_scholes.call_price(s, k, t, r, sigma)
        
        times = []
        for _ in range(self.measure_runs):
            start = time.perf_counter()
            black_scholes.call_price(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        qf_time = np.median(times)  # ä¸­å¤®å€¤ã‚’ä½¿ç”¨ï¼ˆå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›ï¼‰
        results["quantforge"] = qf_time
        
        # Pure Pythonï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼‰
        for _ in range(min(self.warmup_runs, 10)):  # é…ã„ã®ã§å°‘ãªã‚
            black_scholes_pure_python(s, k, t, r, sigma)
            
        times = []
        for _ in range(min(self.measure_runs, 100)):  # é…ã„ã®ã§å°‘ãªã‚
            start = time.perf_counter()
            black_scholes_pure_python(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        py_time = np.median(times)
        results["pure_python"] = py_time
        
        # SciPyï¼ˆä¸€èˆ¬çš„ãªå®Ÿè£…ï¼‰
        for _ in range(self.warmup_runs):
            black_scholes_scipy_single(s, k, t, r, sigma)
            
        times = []
        for _ in range(self.measure_runs):
            start = time.perf_counter()
            black_scholes_scipy_single(s, k, t, r, sigma)
            times.append(time.perf_counter() - start)
        scipy_time = np.median(times)
        results["scipy"] = scipy_time
        
        # ç›¸å¯¾æ€§èƒ½è¨ˆç®—
        results["speedup_vs_pure_python"] = py_time / qf_time
        results["speedup_vs_scipy"] = scipy_time / qf_time
        
        return results
    
    def benchmark_batch(self, size: int) -> Dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯."""
        spots = np.random.uniform(50, 150, size).astype(np.float64)
        spots_list = spots.tolist()  # Pure Pythonç”¨
        k, t, r, sigma = 100.0, 1.0, 0.05, 0.2
        
        results = {"size": size}
        
        # QuantForge
        _ = black_scholes.call_price_batch(spots[:min(100, size)], k, t, r, sigma)
        start = time.perf_counter()
        _ = black_scholes.call_price_batch(spots, k, t, r, sigma)
        qf_time = time.perf_counter() - start
        results["quantforge"] = qf_time
        
        # NumPy Batch
        _ = black_scholes_numpy_batch(spots[:min(100, size)], k, t, r, sigma)
        start = time.perf_counter()
        _ = black_scholes_numpy_batch(spots, k, t, r, sigma)
        np_time = time.perf_counter() - start
        results["numpy_batch"] = np_time
        
        # Pure Python (å°ã•ã„ã‚µã‚¤ã‚ºã®ã¿)
        if size <= 1000:
            start = time.perf_counter()
            _ = black_scholes_pure_python_batch(spots_list, k, t, r, sigma)
            py_time = time.perf_counter() - start
            results["pure_python"] = py_time
            results["speedup_vs_pure_python"] = py_time / qf_time
        
        # ç›¸å¯¾æ€§èƒ½ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        results["speedup_vs_numpy"] = np_time / qf_time
        results["throughput_qf"] = size / qf_time
        results["throughput_np"] = size / np_time
            
        return results
    
    def run_all(self) -> Dict[str, Any]:
        """å…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ."""
        print("ğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹...")
        
        results = {
            "system_info": self.get_system_info(),
            "single": {},
            "batch": []
        }
        
        print("ğŸ“Š å˜ä¸€è¨ˆç®—ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
        results["single"] = self.benchmark_single()
        
        print("ğŸ“Š ãƒãƒƒãƒå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
        for size in [100, 1000, 10000, 100000, 1000000]:
            print(f"  - ã‚µã‚¤ã‚º {size:,} ...")
            results["batch"].append(self.benchmark_batch(size))
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open("benchmark_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print("âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        return results

if __name__ == "__main__":
    runner = BenchmarkRunner()
    results = runner.run_all()
    
    # ç°¡æ˜“çµæœè¡¨ç¤º
    print("\n=== çµæœã‚µãƒãƒª ===")
    single = results["single"]
    print(f"å˜ä¸€è¨ˆç®—: QuantForgeã¯Pure Pythonã‚ˆã‚Š{single['speedup_vs_pure_python']:.0f}å€é«˜é€Ÿ")
    
    batch_1m = next((b for b in results["batch"] if b["size"] == 1000000), None)
    if batch_1m:
        print(f"100ä¸‡ä»¶ãƒãƒƒãƒ: QuantForgeã¯NumPyã‚ˆã‚Š{batch_1m['speedup_vs_numpy']:.1f}å€é«˜é€Ÿ")
        print(f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {batch_1m['throughput_qf']/1e6:.1f}M ops/sec")
```

#### 2.3 å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆbenchmarks/run_benchmarks.shï¼‰
```bash
#!/bin/bash
set -e

echo "ğŸš€ QuantForge Black-Scholesãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"
echo "==========================================="
date

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$( cd "$SCRIPT_DIR/.." && pwd )"

# Rustãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ï¼‰
echo ""
echo "ğŸ“Š Rustãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"
echo "------------------------------"
cd "$PROJECT_ROOT"
cargo bench --bench benchmark -- black_scholes 2>&1 | grep -E "time:|throughput:" || true

# Pythonæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆbenchmarksãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ï¼‰
echo ""
echo "ğŸ“Š Pythonæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"
echo "------------------------"
cd "$SCRIPT_DIR"
uv run python run_comparison.py

# çµæœã‚’Markdownå½¢å¼ã§å‡ºåŠ›
echo ""
echo "ğŸ“ çµæœã‚’Markdownå½¢å¼ã§ä¿å­˜ä¸­..."
uv run python format_results.py > "$PROJECT_ROOT/docs/performance/benchmarks_$(date +%Y%m%d).md"

echo ""
echo "âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†"
echo "çµæœ: docs/performance/benchmarks_$(date +%Y%m%d).md"
```

#### 2.4 çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ï¼ˆbenchmarks/format_results.pyï¼‰
```python
"""ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’Markdownå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ."""

import json
from datetime import datetime
from pathlib import Path

def format_time(seconds: float) -> str:
    """æ™‚é–“ã‚’é©åˆ‡ãªå˜ä½ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ."""
    if seconds < 1e-6:
        return f"{seconds*1e9:.1f} ns"
    elif seconds < 1e-3:
        return f"{seconds*1e6:.2f} Î¼s"
    elif seconds < 1:
        return f"{seconds*1e3:.2f} ms"
    else:
        return f"{seconds:.2f} s"

def format_markdown(results: dict) -> str:
    """çµæœã‚’Markdownå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ."""
    md = []
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    md.append("# Black-Scholesãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
    md.append("")
    md.append(f"æ¸¬å®šæ—¥æ™‚: {results['system_info']['timestamp']}")
    md.append("")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    md.append("## æ¸¬å®šç’°å¢ƒ")
    md.append("")
    info = results["system_info"]
    md.append(f"- **ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **: {info['platform']}")
    md.append(f"- **CPU**: {info['processor']}")
    md.append(f"- **ã‚³ã‚¢æ•°**: {info['cpu_count']} (è«–ç†: {info['cpu_count_logical']})")
    md.append(f"- **ãƒ¡ãƒ¢ãƒª**: {info['memory_gb']} GB")
    md.append(f"- **Python**: {info['python_version']}")
    md.append("")
    
    # å˜ä¸€è¨ˆç®—çµæœ
    md.append("## å˜ä¸€è¨ˆç®—æ€§èƒ½")
    md.append("")
    md.append("### å®Ÿæ¸¬å€¤")
    single = results["single"]
    md.append("| å®Ÿè£… | æ™‚é–“ | èª¬æ˜ |")
    md.append("|------|------|------|")
    md.append(f"| QuantForge (Rust) | {format_time(single['quantforge'])} | æœ€é©åŒ–ã•ã‚ŒãŸRustå®Ÿè£… |")
    md.append(f"| SciPy | {format_time(single['scipy'])} | ä¸€èˆ¬çš„ãªPythonå®Ÿè£… |")
    md.append(f"| Pure Python | {format_time(single['pure_python'])} | å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã— |")
    md.append("")
    
    md.append("### ç›¸å¯¾æ€§èƒ½")
    md.append("| æ¯”è¼ƒ | é«˜é€ŸåŒ–ç‡ |")
    md.append("|------|----------|")
    md.append(f"| QuantForge vs Pure Python | **{single['speedup_vs_pure_python']:.0f}å€** é«˜é€Ÿ |")
    md.append(f"| QuantForge vs SciPy | **{single['speedup_vs_scipy']:.1f}å€** é«˜é€Ÿ |")
    md.append("")
    
    # ãƒãƒƒãƒå‡¦ç†çµæœ
    md.append("## ãƒãƒƒãƒå‡¦ç†æ€§èƒ½")
    md.append("")
    md.append("| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | QuantForge | NumPy | Pure Python | QFé«˜é€ŸåŒ–ç‡ | QFã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ |")
    md.append("|-------------|------------|-------|-------------|-----------|----------------|")
    
    for batch in results["batch"]:
        size = batch['size']
        qf_time = format_time(batch['quantforge'])
        np_time = format_time(batch['numpy_batch'])
        
        if 'pure_python' in batch:
            py_time = format_time(batch['pure_python'])
            py_speedup = f"{batch['speedup_vs_pure_python']:.0f}x"
        else:
            py_time = "N/A"
            py_speedup = "-"
        
        np_speedup = batch['speedup_vs_numpy']
        throughput = batch['throughput_qf'] / 1e6
        
        md.append(f"| {size:,} | {qf_time} | {np_time} | {py_time} | "
                 f"NumPy: {np_speedup:.1f}x | {throughput:.1f}M ops/sec |")
    
    md.append("")
    
    # è¦ç´„
    md.append("## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ç´„")
    md.append("")
    
    # å˜ä¸€è¨ˆç®—ã®è¦ç´„
    md.append("### å˜ä¸€è¨ˆç®—")
    md.append(f"- QuantForgeã¯Pure Pythonã‚ˆã‚Š**{results['single']['speedup_vs_pure_python']:.0f}å€**é«˜é€Ÿ")
    md.append(f"- QuantForgeã¯SciPyã‚ˆã‚Š**{results['single']['speedup_vs_scipy']:.1f}å€**é«˜é€Ÿ")
    md.append("")
    
    # ãƒãƒƒãƒå‡¦ç†ã®è¦ç´„
    md.append("### ãƒãƒƒãƒå‡¦ç†ï¼ˆ100ä¸‡ä»¶ï¼‰")
    batch_1m = next((b for b in results['batch'] if b['size'] == 1000000), None)
    if batch_1m:
        md.append(f"- QuantForgeã¯NumPyã‚ˆã‚Š**{batch_1m['speedup_vs_numpy']:.0f}å€**é«˜é€Ÿ")
        md.append(f"- å®Ÿæ¸¬ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: **{batch_1m['throughput_qf']/1e6:.1f}M ops/sec**")
        md.append(f"- å‡¦ç†æ™‚é–“: {format_time(batch_1m['quantforge'])}")
    md.append("")
    
    # æ³¨è¨˜
    md.append("## æ¸¬å®šæ–¹æ³•")
    md.append("")
    md.append("- **æ¸¬å®šå›æ•°**: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—100å›å¾Œã€1000å›æ¸¬å®šã®ä¸­å¤®å€¤")
    md.append("- **Pure Python**: å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãªã„å®Ÿè£…")
    md.append("- **SciPy**: scipy.stats.normã‚’ä½¿ç”¨ã—ãŸä¸€èˆ¬çš„ãªå®Ÿè£…")
    md.append("- **NumPy**: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒãƒƒãƒå‡¦ç†å®Ÿè£…")
    md.append("- **QuantForge**: Rust + SIMDæœ€é©åŒ–å®Ÿè£…")
    md.append("")
    
    md.append("## å†ç¾æ–¹æ³•")
    md.append("")
    md.append("```bash")
    md.append("# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰")
    md.append("cd benchmarks")
    md.append("./run_benchmarks.sh")
    md.append("")
    md.append("# ã¾ãŸã¯å€‹åˆ¥å®Ÿè¡Œ")
    md.append("cd benchmarks")
    md.append("uv run python run_comparison.py")
    md.append("uv run python format_results.py")
    md.append("```")
    md.append("")
    
    return "\n".join(md)

if __name__ == "__main__":
    # å‰å›ã®å®Ÿè¡Œçµæœã‚’èª­ã¿è¾¼ã¿
    with open("benchmark_results.json", "r") as f:
        results = json.load(f)
    
    # Markdownå½¢å¼ã§å‡ºåŠ›
    print(format_markdown(results))
```

### Phase 3: ãƒ†ã‚¹ãƒˆä½œæˆï¼ˆ1æ™‚é–“ï¼‰
- [ ] ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆ
- [ ] çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã®ãƒ†ã‚¹ãƒˆ
- [ ] æ¯”è¼ƒå®Ÿè£…ã®æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆï¼ˆå€¤ã®ä¸€è‡´ç¢ºèªï¼‰

```python
# tests/test_benchmark_implementations.py
"""ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè£…ã®æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ."""

import pytest
import numpy as np
from benchmarks.python_baseline import (
    black_scholes_pure_python,
    black_scholes_scipy_single,
    black_scholes_numpy_batch
)
from quantforge.models import black_scholes

def test_implementations_consistency():
    """å„å®Ÿè£…ã®çµæœãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª."""
    s, k, t, r, sigma = 100.0, 100.0, 1.0, 0.05, 0.2
    
    # å„å®Ÿè£…ã®çµæœ
    qf_result = black_scholes.call_price(s, k, t, r, sigma)
    pure_result = black_scholes_pure_python(s, k, t, r, sigma)
    scipy_result = black_scholes_scipy_single(s, k, t, r, sigma)
    
    # èª¤å·®1%ä»¥å†…ã§ä¸€è‡´
    assert abs(qf_result - scipy_result) / scipy_result < 0.01
    assert abs(pure_result - scipy_result) / scipy_result < 0.01
```

### Phase 4: å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆ30åˆ†ï¼‰
```bash
# Pythonå“è³ªãƒã‚§ãƒƒã‚¯
cd benchmarks
uv run ruff format .
uv run ruff check .
uv run mypy --strict .

# é‡è¤‡ãƒã‚§ãƒƒã‚¯
similarity-py --threshold 0.80 --min-lines 5 .
```

### Phase 5: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ï¼ˆ1æ™‚é–“ï¼‰
- [ ] docs/performance/benchmarks.mdã®æ›´æ–°
- [ ] æ¸¬å®šæ–¹æ³•ã®æ–‡æ›¸åŒ–
- [ ] å†ç¾æ‰‹é †ã®è¨˜è¼‰

## å‘½åå®šç¾©ã‚»ã‚¯ã‚·ãƒ§ãƒ³

### ä½¿ç”¨ã™ã‚‹æ—¢å­˜å‘½å
```yaml
existing_names:
  - name: "s"
    meaning: "ã‚¹ãƒãƒƒãƒˆä¾¡æ ¼"
    source: "naming_conventions.md#å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
  - name: "k"
    meaning: "æ¨©åˆ©è¡Œä½¿ä¾¡æ ¼"
    source: "naming_conventions.md#å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
  - name: "t"
    meaning: "æº€æœŸã¾ã§ã®æ™‚é–“"
    source: "naming_conventions.md#å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
  - name: "r"
    meaning: "ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ"
    source: "naming_conventions.md#å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
  - name: "sigma"
    meaning: "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£"
    source: "naming_conventions.md#å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
  - name: "call_price"
    meaning: "ã‚³ãƒ¼ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼è¨ˆç®—"
    source: "æ—¢å­˜ã®Black-Scholesãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
  - name: "call_price_batch"
    meaning: "ãƒãƒƒãƒå‡¦ç†ç‰ˆ"
    source: "æ—¢å­˜ã®Black-Scholesãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
```

### æ–°è¦ææ¡ˆå‘½å
```yaml
proposed_names:
  - name: "python_baseline"
    meaning: "Pythonæ¯”è¼ƒç”¨åŸºæº–å®Ÿè£…"
    justification: "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å°‚ç”¨ã®ãŸã‚æ˜ç¢ºãªåå‰"
    status: "å†…éƒ¨ä½¿ç”¨ã®ã¿"
  - name: "run_comparison"
    meaning: "æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"
    justification: "ç›®çš„ã‚’æ˜ç¢ºã«ç¤ºã™åå‰"
    status: "ã‚¹ã‚¯ãƒªãƒ—ãƒˆåã¨ã—ã¦ä½¿ç”¨"
  - name: "erf_approx"
    meaning: "èª¤å·®é–¢æ•°ã®è¿‘ä¼¼"
    justification: "æ•°å­¦çš„æ¨™æº–åç§°"
    status: "Pure Pythonå†…éƒ¨å®Ÿè£…"
  - name: "norm_cdf_pure"
    meaning: "ç´¯ç©æ­£è¦åˆ†å¸ƒé–¢æ•°ã®Pure Pythonå®Ÿè£…"
    justification: "å®Ÿè£…æ–¹æ³•ã‚’æ˜ç¢ºã«ç¤ºã™"
    status: "Pure Pythonå†…éƒ¨å®Ÿè£…"
```

### å‘½åã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [x] æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¨ã®æ•´åˆæ€§ç¢ºèª
- [x] naming_conventions.mdã¨ã®ä¸€è‡´ç¢ºèª
- [x] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã®ä½¿ç”¨æ–¹æ³•å®šç¾©
- [x] APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯çœç•¥å½¢ã‚’ä½¿ç”¨
- [x] ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚‚APIåã‚’ä½¿ç”¨

## ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

| ãƒªã‚¹ã‚¯ | å½±éŸ¿åº¦ | å¯¾ç­– |
|--------|--------|------|
| æ¸¬å®šå€¤ã®ã°ã‚‰ã¤ã | ä¸­ | ä¸­å¤®å€¤ä½¿ç”¨ã€è¤‡æ•°å›æ¸¬å®š |
| ç’°å¢ƒä¾å­˜æ€§ | ä½ | ç’°å¢ƒæƒ…å ±ã®è©³ç´°è¨˜éŒ² |
| Pythonã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | ä¸­ | ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œ |
| Pure Pythonå®Ÿè£…ã®ç²¾åº¦ | ä½ | Abramowitzè¿‘ä¼¼ã®ä½¿ç”¨ |

## æˆæœç‰©

- [ ] benchmarks/python_baseline.py - Pythonæ¯”è¼ƒå®Ÿè£…ï¼ˆPure/SciPy/NumPyï¼‰
- [ ] benchmarks/run_comparison.py - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
- [ ] benchmarks/format_results.py - çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿
- [ ] benchmarks/run_benchmarks.sh - çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- [ ] docs/performance/benchmarks_YYYYMMDD.md - æ¸¬å®šçµæœ
- [ ] tests/test_benchmark_implementations.py - å®Ÿè£…ãƒ†ã‚¹ãƒˆ

## å®Œäº†æ¡ä»¶

- [ ] Pure Pythonå®Ÿè£…ï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼‰
- [ ] å®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹ã®æ€§èƒ½ãƒ‡ãƒ¼ã‚¿
- [ ] Python/SciPy/NumPyã¨ã®ç›¸å¯¾æ¯”è¼ƒ
- [ ] å†ç¾å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰
- [ ] å…¬æ­£ã§é€æ˜æ€§ã®ã‚ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ ] å“è³ªã‚²ãƒ¼ãƒˆï¼ˆruff, mypyï¼‰é€šé

## å‚™è€ƒ

- **Pure Python**: math ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ä½¿ç”¨ã€scipy/numpyä¸ä½¿ç”¨
- **Dockerç’°å¢ƒ**: åˆ¥è¨ˆç”»ã§å®Ÿæ–½
- **Black-Scholesãƒ¢ãƒ‡ãƒ«ã®ã¿**: ä»–ãƒ¢ãƒ‡ãƒ«ã¯å¯¾è±¡å¤–
- **å®Ÿç’°å¢ƒé‡è¦–**: ç†è«–å€¤ã§ã¯ãªãå®Ÿæ¸¬å€¤
- **ç›¸å¯¾æ€§èƒ½å¼·èª¿**: çµ¶å¯¾å€¤ã‚ˆã‚Šå€ç‡ã‚’é‡è¦–