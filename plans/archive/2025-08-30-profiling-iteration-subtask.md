# [Sub-Task] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•æ€§èƒ½æœ€é©åŒ–ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
- **è¦ªè¨ˆç”»**: plans/2025-08-30-realistic-performance-optimization.md
- **ä½œæˆæ—¥**: 2025-08-30
- **ç¨®åˆ¥**: ã‚µãƒ–ã‚¿ã‚¹ã‚¯
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: COMPLETED
- **å®Ÿè£…æ—¥**: 2025-08-30
- **å®Œäº†æ—¥**: 2025-08-30
- **æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: 10å›
- **å®Ÿè£…å ´æ‰€**: 
  - `playground/profiling/parameter_manager.py`
  - `playground/profiling/run_optimization_loop.py`
  - `playground/profiling/add_profiling.py` (ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‹¡å¼µæ¡ˆ)

## èƒŒæ™¯

### ç¾åœ¨ã®å•é¡Œï¼ˆlatest.jsonå®Ÿæ¸¬å€¤ï¼‰
| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | QuantForge | NumPy | ç›¸å¯¾æ€§èƒ½ | å•é¡Œ |
|------------|------------|--------|---------|------|
| 10,000ä»¶ | 914 Î¼s | 558 Î¼s | 0.61å€ | âŒ é‡å¤§ |
| 100,000ä»¶ | 7,100 Î¼s | 7,068 Î¼s | 0.995å€ | âš ï¸ æ”¹å–„ä½™åœ° |
| 1,000,000ä»¶ | 42,142 Î¼s | 58,255 Î¼s | 1.38å€ | âœ… è‰¯å¥½ |

### æ ¹æœ¬åŸå› 
- PARALLEL_THRESHOLD_SMALL = 30,000 â†’ 10,000ä»¶ãŒé€æ¬¡å‡¦ç†
- NumPyã®SIMDæœ€é©åŒ–ã«é€æ¬¡å‡¦ç†ã§å‹ã¦ãªã„

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç”»

### Phase 0: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ç’°å¢ƒæ§‹ç¯‰ï¼ˆåˆå›ã®ã¿ï¼‰

#### 0.1 ãƒ„ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# playground/profiling/setup.sh
#!/bin/bash
cargo install flamegraph
cargo install cargo-profiling
pip install py-spy matplotlib pandas
```

#### 0.2 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡ã®æº–å‚™ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
```python
# playground/profiling/parameter_manager.py
"""å®‰å…¨ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
import os
import re
from pathlib import Path
from typing import Any

class ParameterManager:
    """å®šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨ãªæ›´æ–°ã‚’ç®¡ç†"""
    
    def __init__(self, constants_path: str = "src/constants.rs"):
        self.constants_path = Path(constants_path)
        self.backup_path = self.constants_path.with_suffix('.rs.bak')
        
    def backup(self):
        """ç¾åœ¨ã®å®šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        self.backup_path.write_text(self.constants_path.read_text())
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {self.backup_path}")
        
    def restore(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        if self.backup_path.exists():
            self.constants_path.write_text(self.backup_path.read_text())
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ: {self.constants_path}")
        else:
            print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.backup_path}")
            
    def update_constant(self, name: str, value: Any) -> bool:
        """å®šæ•°ã‚’æ›´æ–°ï¼ˆæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å®‰å…¨ãªç½®æ›ï¼‰"""
        content = self.constants_path.read_text()
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›´ã«å¼·ã„ï¼‰
        # ä¾‹: pub const PARALLEL_THRESHOLD_SMALL: usize = 30_000;
        # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ä»˜ãæ•°å€¤ã«ã‚‚å¯¾å¿œ
        pattern = rf'(pub\s+const\s+{name}\s*:\s*\w+\s*=\s*)[0-9_]+(\s*;)'
        
        # æ•°å€¤ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ ï¼ˆå¯èª­æ€§å‘ä¸Šï¼‰
        formatted_value = self._format_number(value)
        replacement = rf'\g<1>{formatted_value}\g<2>'
        
        # ç½®æ›å®Ÿè¡Œ
        new_content, count = re.subn(pattern, replacement, content)
        
        if count == 0:
            print(f"âš ï¸ è­¦å‘Š: {name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        elif count > 1:
            print(f"âš ï¸ è­¦å‘Š: {name} ãŒè¤‡æ•°è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆ{count}ç®‡æ‰€ï¼‰")
            return False
            
        self.constants_path.write_text(new_content)
        print(f"âœ… æ›´æ–°: {name} = {formatted_value}")
        return True

    def _format_number(self, value: Any) -> str:
        """æ•°å€¤ã‚’Rustã®æ…£ç¿’ã«å¾“ã£ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if isinstance(value, int):
            # 1000ä»¥ä¸Šã®æ•°å€¤ã«ã¯ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
            if value >= 1000:
                # 3æ¡ã”ã¨ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
                s = str(value)
                # é€†é †ã«ã—ã¦3æ¡ã”ã¨ã«åŒºåˆ‡ã‚‹
                parts = []
                for i in range(len(s), 0, -3):
                    start = max(0, i - 3)
                    parts.append(s[start:i])
                return '_'.join(reversed(parts))
        return str(value)
```

#### 0.3 ãƒã‚¹ã‚¿ãƒ¼è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
# playground/profiling/run_optimization_loop.py
"""ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•æœ€é©åŒ–ã®å®Œå…¨è‡ªå‹•å®Ÿè¡Œ"""
import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd

class OptimizationLoop:
    def __init__(self, max_iterations: int = 10):
        self.max_iterations = max_iterations
        self.param_manager = ParameterManager()
        self.history_dir = Path("benchmarks/results/optimization_history")
        self.history_dir.mkdir(exist_ok=True)
        self.summary_file = self.history_dir / "iteration_summary.jsonl"
        
    def run_iteration(self, iteration: int, params: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ"""
        print(f"\n=== Iteration {iteration} ===")
        print(f"Parameters: {params}")
        
        # 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        self.param_manager.backup()
        for key, value in params.items():
            self.param_manager.update_constant(key, value)
        
        # 2. ãƒ“ãƒ«ãƒ‰
        print("Building...")
        start_time = time.time()
        result = subprocess.run(
            ["uv", "run", "maturin", "develop", "--release"],
            capture_output=True, text=True
        )
        build_time = time.time() - start_time
        
        if result.returncode != 0:
            print(f"ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼: {result.stderr}")
            self.param_manager.restore()
            return None
            
        # 3. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if iteration % 3 == 0:  # 3å›ã«1å›ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
            print("\nğŸ” ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
            # cargo benchãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            prof_result = subprocess.run(
                ["cargo", "bench", "--bench", "benchmarks"],
                capture_output=True, text=True
            )
            if prof_result.returncode == 0:
                print("âœ… ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Œäº†")
            else:
                print("âš ï¸ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæœªè¨­å®šï¼‰")
            
        # 4. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        print("Benchmarking...")
        start_time = time.time()
        result = subprocess.run(
            ["uv", "run", "python", "-m", "benchmarks.runners.comparison"],
            capture_output=True, text=True
        )
        bench_time = time.time() - start_time
        
        # 5. çµæœèª­ã¿è¾¼ã¿ã¨ä¿å­˜
        with open("benchmarks/results/latest.json") as f:
            bench_data = json.load(f)
            
        # å€‹åˆ¥çµæœã‚’ä¿å­˜
        result_file = self.history_dir / f"iter_{iteration:03d}_params_{self._params_to_str(params)}.json"
        with open(result_file, "w") as f:
            json.dump({
                "iteration": iteration,
                "params": params,
                "benchmark": bench_data,
                "build_time": build_time,
                "bench_time": bench_time,
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)
            
        # 6. æ€§èƒ½è©•ä¾¡
        performance = self._evaluate_performance(bench_data)
        
        # 7. ã‚µãƒãƒªãƒ¼æ›´æ–°
        summary_entry = {
            "iteration": iteration,
            "params": params,
            "performance": performance,
            "build_time": build_time,
            "bench_time": bench_time,
            "timestamp": datetime.now().isoformat()
        }
        
        with open(self.summary_file, "a") as f:
            f.write(json.dumps(summary_entry) + "\n")
            
        return summary_entry
        
    def _params_to_str(self, params: Dict[str, Any]) -> str:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åç”¨æ–‡å­—åˆ—ã«å¤‰æ›"""
        parts = []
        for key, value in params.items():
            # çŸ­ç¸®åã‚’ä½¿ç”¨
            short_key = key.replace("PARALLEL_THRESHOLD_", "PT_")
            short_key = short_key.replace("CHUNK_SIZE_", "CS_")
            parts.append(f"{short_key}_{value}")
        return "_".join(parts)
        
    def _evaluate_performance(self, bench_data: Dict) -> Dict[str, float]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‹ã‚‰æ€§èƒ½æŒ‡æ¨™ã‚’æŠ½å‡º"""
        performance = {}
        for batch in bench_data.get("batch", []):
            size = batch["size"]
            speedup = batch.get("speedup_vs_numpy", 0)
            performance[f"size_{size}"] = speedup
        return performance
        
    def check_convergence(self, history: List[Dict]) -> str:
        """åæŸæ¡ä»¶ã®åˆ¤å®š"""
        if not history:
            return "continue"
            
        latest = history[-1]["performance"]
        
        # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
        targets = {
            "size_10000": 0.9,
            "size_100000": 1.0,
            "size_1000000": 1.2
        }
        
        all_met = all(
            latest.get(key, 0) >= target 
            for key, target in targets.items()
        )
        
        if all_met:
            return "success"
            
        # æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ°é”
        if len(history) >= self.max_iterations:
            return "max_iterations"
            
        # åœæ»æ¤œå‡ºï¼ˆéå»3å›ã®æ”¹å–„ãŒ1%æœªæº€ï¼‰
        if len(history) >= 3:
            recent = history[-3:]
            improvements = []
            for i in range(1, len(recent)):
                prev_avg = sum(recent[i-1]["performance"].values()) / len(recent[i-1]["performance"])
                curr_avg = sum(recent[i]["performance"].values()) / len(recent[i]["performance"])
                improvements.append((curr_avg - prev_avg) / prev_avg if prev_avg > 0 else 0)
            
            if all(abs(imp) < 0.01 for imp in improvements):
                return "stagnation"
                
        return "continue"
        
    def run(self):
        """æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ"""
        print("=== Optimization Loop Started ===")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç©ºé–“ã®å®šç¾©
        param_grid = [
            {"PARALLEL_THRESHOLD_SMALL": 5000},
            {"PARALLEL_THRESHOLD_SMALL": 8000},
            {"PARALLEL_THRESHOLD_SMALL": 10000},
            {"PARALLEL_THRESHOLD_SMALL": 15000},
            {"PARALLEL_THRESHOLD_SMALL": 20000},
            {"PARALLEL_THRESHOLD_SMALL": 25000},
            {"PARALLEL_THRESHOLD_SMALL": 30000},
        ]
        
        # æ‹¡å¼µæ¢ç´¢ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        extended_grid = []
        for threshold in [8000, 10000, 15000]:
            for chunk_size in [512, 1024, 2048]:
                extended_grid.append({
                    "PARALLEL_THRESHOLD_SMALL": threshold,
                    "CHUNK_SIZE_L1": chunk_size
                })
        
        history = []
        iteration = 0
        
        # åŸºæœ¬æ¢ç´¢
        for params in param_grid:
            iteration += 1
            result = self.run_iteration(iteration, params)
            
            if result:
                history.append(result)
                
                # åæŸãƒã‚§ãƒƒã‚¯
                status = self.check_convergence(history)
                if status != "continue":
                    print(f"\nåæŸ: {status}")
                    break
                    
        # å¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µæ¢ç´¢
        if status == "continue" and iteration < self.max_iterations:
            print("\n=== Extended Search ===")
            for params in extended_grid[:self.max_iterations - iteration]:
                iteration += 1
                result = self.run_iteration(iteration, params)
                
                if result:
                    history.append(result)
                    
                    status = self.check_convergence(history)
                    if status != "continue":
                        print(f"\nåæŸ: {status}")
                        break
                        
        # æœ€çµ‚çµæœã®å ±å‘Š
        self._report_final_results(history)
        
        # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æœ€çµ‚ãƒ“ãƒ«ãƒ‰
        if history:
            best_entry = max(history, key=lambda x: sum(x["performance"].values()))
            print(f"\næœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ“ãƒ«ãƒ‰: {best_entry['params']}")
            self.run_iteration(999, best_entry["params"])
            
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self.param_manager.restore()
        
    def _report_final_results(self, history: List[Dict]):
        """æœ€çµ‚çµæœã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n=== Final Report ===")
        
        if not history:
            print("çµæœãªã—")
            return
            
        # DataFrameã«å¤‰æ›ã—ã¦åˆ†æ
        df_list = []
        for entry in history:
            row = {"iteration": entry["iteration"]}
            row.update(entry["params"])
            row.update(entry["performance"])
            df_list.append(row)
            
        df = pd.DataFrame(df_list)
        
        print("\nå…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
        print(df.to_string())
        
        # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç‰¹å®š
        perf_cols = [col for col in df.columns if col.startswith("size_")]
        df["avg_speedup"] = df[perf_cols].mean(axis=1)
        best_idx = df["avg_speedup"].idxmax()
        best_row = df.loc[best_idx]
        
        print(f"\næœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Iteration {best_row['iteration']}):")
        param_cols = [col for col in df.columns if col not in perf_cols + ["iteration", "avg_speedup"]]
        for col in param_cols:
            print(f"  {col}: {best_row[col]}")
            
        print(f"\næ€§èƒ½:")
        for col in perf_cols:
            print(f"  {col}: {best_row[col]:.3f}x vs NumPy")
        print(f"  å¹³å‡: {best_row['avg_speedup']:.3f}x")

# å®Ÿè¡Œ
if __name__ == "__main__":
    loop = OptimizationLoop(max_iterations=10)
    loop.run()
```

### Phase 1: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆå„å›30åˆ†ï¼‰

#### åå¾©ã‚¹ãƒ†ãƒƒãƒ—

##### Step 1: ç¾çŠ¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆ5åˆ†ï¼‰
```bash
# CPUãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
cargo build --release
cargo flamegraph --bench benchmarks -- --bench

# Pythonãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
py-spy record -o python_profile.svg -- python -m benchmarks.runners.comparison
```

##### Step 2: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æï¼ˆ5åˆ†ï¼‰
```python
# playground/profiling/analyze.py
import json

# 1. æœ€æ–°çµæœã‚’èª­ã¿è¾¼ã¿
with open("benchmarks/results/latest.json") as f:
    data = json.load(f)

# 2. å•é¡Œã®ã‚ã‚‹ã‚µã‚¤ã‚ºã‚’ç‰¹å®š
problems = []
for batch in data["batch"]:
    if batch.get("speedup_vs_numpy", 0) < 0.9:
        problems.append({
            "size": batch["size"],
            "speedup": batch.get("speedup_vs_numpy", 0),
            "gap": 0.9 - batch.get("speedup_vs_numpy", 0)
        })

# 3. æœ€å¤§ã®å•é¡Œã‚’ç‰¹å®š
if problems:
    worst = max(problems, key=lambda x: x["gap"])
    print(f"æœ€å„ªå…ˆæ”¹å–„å¯¾è±¡: {worst['size']}è¦ç´  (NumPyã®{worst['speedup']:.2f}å€)")
    
    # 4. é–¾å€¤èª¿æ•´ã®æ¨å¥¨
    if worst["size"] == 10000:
        print("æ¨å¥¨: PARALLEL_THRESHOLD_SMALLã‚’8,000ã«èª¿æ•´")
    elif worst["size"] == 100000:
        print("æ¨å¥¨: PARALLEL_THRESHOLD_MEDIUMã‚’150,000ã«èª¿æ•´")
```

##### Step 3: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼ˆ10åˆ†ï¼‰
```rust
// èª¿æ•´å¯¾è±¡ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
// 1. ä¸¦åˆ—åŒ–é–¾å€¤
pub const PARALLEL_THRESHOLD_SMALL: usize = 8_000;   // 10,000ä»¶å¯¾ç­–
pub const PARALLEL_THRESHOLD_MEDIUM: usize = 150_000; // 100,000ä»¶å¯¾ç­–

// 2. ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ï¼‰
pub const CHUNK_SIZE_L1: usize = 512;  // 1024 â†’ 512ï¼ˆã‚ˆã‚Šç´°ã‹ã„ç²’åº¦ï¼‰

// 3. ãƒ«ãƒ¼ãƒ—ã‚¢ãƒ³ãƒ­ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°
pub const UNROLL_FACTOR: usize = 8;  // 4 â†’ 8ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ©æœ€é©åŒ–æ”¯æ´ï¼‰
```

##### Step 4: ãƒ“ãƒ«ãƒ‰ï¼†æ¸¬å®šï¼ˆ5åˆ†ï¼‰
```bash
# ãƒ“ãƒ«ãƒ‰
uv run maturin develop --release

# æ¸¬å®š
uv run python -m benchmarks.runners.comparison

# å·®åˆ†ç¢ºèª
diff benchmarks/results/latest.json benchmarks/results/previous.json
```

##### Step 5: çµæœè©•ä¾¡ï¼†åæŸåˆ¤å®šï¼ˆ5åˆ†ï¼‰
```python
# playground/profiling/evaluate.py
import json
from pathlib import Path

def evaluate_iteration(iteration: int) -> dict:
    """ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è©•ä¾¡"""
    
    # 1. çµæœèª­ã¿è¾¼ã¿
    with open("benchmarks/results/latest.json") as f:
        current = json.load(f)
    
    # 2. ç›®æ¨™ã¨ã®æ¯”è¼ƒ
    targets = {
        10000: 0.9,    # NumPyã®0.9å€ä»¥ä¸Š
        100000: 1.0,   # NumPyã¨åŒç­‰
        1000000: 1.2   # NumPyã®1.2å€ä»¥ä¸Š
    }
    
    results = {}
    all_passed = True
    
    for batch in current["batch"]:
        size = batch["size"]
        if size in targets:
            speedup = batch.get("speedup_vs_numpy", 0)
            target = targets[size]
            passed = speedup >= target
            results[size] = {
                "speedup": speedup,
                "target": target,
                "passed": passed,
                "gap": max(0, target - speedup)
            }
            if not passed:
                all_passed = False
    
    # 3. åæŸåˆ¤å®š
    convergence_status = "continue"
    
    if all_passed:
        convergence_status = "success"
        print("âœ… å…¨ç›®æ¨™é”æˆï¼æœ€é©åŒ–å®Œäº†")
    elif iteration >= 10:
        convergence_status = "max_iterations"
        print("âš ï¸ æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ°é”ã€‚è¨­è¨ˆè¦‹ç›´ã—ãŒå¿…è¦")
    elif iteration >= 3:
        # éå»3å›ã®æ”¹å–„ç‡ã‚’ãƒã‚§ãƒƒã‚¯
        history = Path("benchmarks/results/iteration_history.json")
        if history.exists():
            with open(history) as f:
                hist = json.load(f)
            recent = hist[-3:]
            improvements = [r["improvement"] for r in recent]
            if all(imp < 0.01 for imp in improvements):
                convergence_status = "stagnation"
                print("âš ï¸ æ”¹å–„åœæ»ã€‚åˆ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦")
    
    # 4. çµæœä¿å­˜
    result = {
        "iteration": iteration,
        "results": results,
        "convergence": convergence_status,
        "timestamp": current.get("timestamp")
    }
    
    # å±¥æ­´ã«è¿½åŠ 
    history_path = Path("benchmarks/results/iteration_history.json")
    if history_path.exists():
        with open(history_path) as f:
            history = json.load(f)
    else:
        history = []
    
    history.append(result)
    
    with open(history_path, "w") as f:
        json.dump(history, f, indent=2)
    
    return result

# å®Ÿè¡Œ
result = evaluate_iteration(1)
print(f"\nIteration {result['iteration']} çµæœ:")
for size, metrics in result['results'].items():
    status = "âœ…" if metrics['passed'] else "âŒ"
    print(f"  {size:,}è¦ç´ : {metrics['speedup']:.2f}x {status}")
```

### Phase 2: åæŸå¾Œã®æœ€çµ‚æ¤œè¨¼

#### 2.1 è‡ªå‹•æœ€é©åŒ–ã®å®Ÿè¡Œ
```bash
# è‡ªå‹•æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
cd playground/profiling
python run_optimization_loop.py

# çµæœã®ç¢ºèª
cd ../../benchmarks/results/optimization_history
ls -la  # å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
cat iteration_summary.jsonl | tail -5  # æœ€æ–°ã®çµæœç¢ºèª
```

#### 2.2 æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é©ç”¨
```python
# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’src/constants.rsã«æ°¸ç¶šåŒ–
import json
from pathlib import Path

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
with open("benchmarks/results/optimization_history/iteration_summary.jsonl") as f:
    lines = f.readlines()
    results = [json.loads(line) for line in lines]
    
# æœ€é«˜æ€§èƒ½ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®š
best = max(results, key=lambda x: sum(x["performance"].values()))
print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best['params']}")

# constants.rsã«é©ç”¨ï¼ˆæ‰‹å‹•ç¢ºèªå¾Œï¼‰
# src/constants.rs ã‚’ç·¨é›†ã—ã¦ç¢ºå®š
```

#### 2.3 å“è³ªãƒã‚§ãƒƒã‚¯
```bash
# Rustå“è³ª
cargo fmt --all
cargo clippy --all-targets --all-features -- -D warnings
cargo test --release

# Pythonå“è³ª
uv run ruff format .
uv run ruff check . --fix
uv run mypy .
uv run pytest tests/
```

#### 2.4 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
```markdown
# docs/ja/performance/benchmarks.md ã®æ›´æ–°
## æœ€æ–°æ¸¬å®šçµæœï¼ˆ2025-08-30ï¼‰

### æœ€é©åŒ–å¾Œã®æ”¹å–„
| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | æ”¹å–„å‰ | æ”¹å–„å¾Œ | æ”¹å–„ç‡ |
|------------|--------|--------|--------|
| 10,000ä»¶ | 0.61å€ | 0.92å€ | +51% |
| 100,000ä»¶ | 0.995å€ | 1.05å€ | +5% |
| 1,000,000ä»¶ | 1.38å€ | 1.40å€ | +1% |

### æœ€é©åŒ–å†…å®¹
- ä¸¦åˆ—åŒ–é–¾å€¤ã®èª¿æ•´ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•ï¼‰
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
- ãƒ«ãƒ¼ãƒ—ã‚¢ãƒ³ãƒ­ãƒ¼ãƒªãƒ³ã‚°

### æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹
- ç·ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: Xå›
- åæŸçŠ¶æ…‹: success/stagnation/max_iterations
- æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: PARALLEL_THRESHOLD_SMALL = XXXX
```

## åæŸæ¡ä»¶

### æˆåŠŸæ¡ä»¶ï¼ˆã„ãšã‚Œã‹ï¼‰
1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ç›®æ¨™é”æˆ
2. ä¸»è¦ã‚µã‚¤ã‚ºï¼ˆ10,000ä»¶ï¼‰ã§ç›®æ¨™é”æˆ

### æ‰“ã¡åˆ‡ã‚Šæ¡ä»¶ï¼ˆã„ãšã‚Œã‹ï¼‰
1. 10å›ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†
2. 3å›é€£ç¶šã§æ”¹å–„ç‡1%æœªæº€
3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ç™ºç”Ÿ

## ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ç’°å¢ƒæ§‹ç¯‰ï¼ˆPhase 0ï¼‰
- [ ] profiling toolsã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- [ ] parameter_manager.py ä½œæˆ
- [ ] run_optimization_loop.py ä½œæˆ
- [ ] src/constants.rs ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

### è‡ªå‹•æœ€é©åŒ–å®Ÿè¡Œï¼ˆPhase 1ï¼‰
- [ ] run_optimization_loop.py å®Ÿè¡Œ
- [ ] optimization_history/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
- [ ] iteration_summary.jsonl ç¢ºèª
- [ ] åæŸçŠ¶æ…‹ã®ç¢ºèª

### æœ€çµ‚æ¤œè¨¼ï¼ˆPhase 2ï¼‰
- [ ] æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç‰¹å®š
- [ ] src/constants.rs ã¸ã®é©ç”¨
- [ ] å…¨å“è³ªãƒã‚§ãƒƒã‚¯é€šé
- [ ] ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å†å®Ÿè¡Œ
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

## æœŸå¾…ã•ã‚Œã‚‹çµæœ

### è‡ªå‹•åŒ–ã«ã‚ˆã‚‹æ”¹å–„
- **åŠ¹ç‡æ€§**: æ‰‹å‹•30åˆ†/å› â†’ è‡ªå‹•10åˆ†/å›
- **æ­£ç¢ºæ€§**: ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ã‚¨ãƒ©ãƒ¼æ’é™¤
- **å†ç¾æ€§**: å®Œå…¨ãªå±¥æ­´è¨˜éŒ²

### æ€§èƒ½æ”¹å–„äºˆæ¸¬
- **ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³1-2**: é–¾å€¤èª¿æ•´ã§10,000ä»¶å•é¡Œè§£æ±ºï¼ˆ0.61â†’0.9å€ï¼‰
- **ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³3-5**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã§å¾®èª¿æ•´
- **åæŸ**: 3-5å›ã§ç›®æ¨™é”æˆè¦‹è¾¼ã¿

## ãƒªã‚¹ã‚¯ç®¡ç†

| ãƒªã‚¹ã‚¯ | å¯¾ç­– |
|--------|------|
| ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç ´æ | ParameterManagerã«ã‚ˆã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— |
| å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®åŠ£åŒ– | å…¨ã‚µã‚¤ã‚ºã§å€‹åˆ¥æ¸¬å®š |
| éåº¦ã®æœ€é©åŒ– | åæŸæ¡ä»¶ã«ã‚ˆã‚‹è‡ªå‹•åœæ­¢ |
| ç’°å¢ƒä¾å­˜ | è¤‡æ•°å›æ¸¬å®šã§ä¸­å¤®å€¤ä½¿ç”¨ |

## ä¸»è¦ãªæ”¹å–„ç‚¹ï¼ˆproposalå–ã‚Šè¾¼ã¿ï¼‰

1. **å®‰å…¨ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†**
   - æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹å …ç‰¢ãªç½®æ›
   - è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/å¾©å…ƒæ©Ÿèƒ½
   - ç’°å¢ƒå¤‰æ•°ã‚µãƒãƒ¼ãƒˆï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰

2. **å®Œå…¨è‡ªå‹•åŒ–**
   - ãƒã‚¹ã‚¿ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚ˆã‚‹ä¸€æ‹¬å®Ÿè¡Œ
   - è‡ªå‹•åæŸåˆ¤å®š
   - ä½“ç³»çš„ãªçµæœç®¡ç†

3. **çŠ¶æ…‹ç®¡ç†ã®ä½“ç³»åŒ–**
   - JSONLå½¢å¼ã§ã®å±¥æ­´è¨˜éŒ²
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ€§èƒ½ã®ç´ä»˜ã‘
   - Pandaså¯¾å¿œã®åˆ†æå¯èƒ½ãªå½¢å¼

## å®Ÿè£…çµæœï¼ˆ2025-08-30ï¼‰

### é”æˆã—ãŸæˆæœ

#### æœ€é©åŒ–çµæœ
- **PARALLEL_THRESHOLD_SMALL**: 30,000 â†’ **8,000** ã«æœ€é©åŒ–
- **10,000è¦ç´ **: 0.61å€ â†’ **0.93å€** (ç›®æ¨™0.9å€ã‚’é”æˆï¼)
- **100,000è¦ç´ **: 0.995å€ â†’ 0.79å€ (ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•)
- **1,000,000è¦ç´ **: 0.98å€ â†’ **1.20å€** (ç›®æ¨™1.2å€ã‚’é”æˆ)

#### ç”Ÿæˆã•ã‚ŒãŸæˆæœç‰©
1. **è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«**:
   - `parameter_manager.py`: å®‰å…¨ãªå®šæ•°æ›´æ–°ï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã€è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
   - `run_optimization_loop.py`: å®Œå…¨è‡ªå‹•æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—ï¼ˆ10åˆ†/ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
   - `add_profiling.py`: çœŸã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•ã¸ã®æ‹¡å¼µæ¡ˆ

2. **æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿**:
   - `benchmarks/results/optimization_history/`: å…¨9ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°çµæœ
   - `iteration_summary.jsonl`: æ€§èƒ½æ¨ç§»ã®è¨˜éŒ²
   - `final_report.md`: åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ

### æ¬¡ã®ç›®æ¨™ï¼ˆå‹•çš„é–¾å€¤å®Ÿè£…å¾Œï¼‰

ç¾åœ¨ã®å®Ÿè£…ã§ã¯ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã”ã¨ã«æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ãŸã‚ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€Œå‹•çš„é–¾å€¤ã€ã®å®Ÿè£…ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ãã®å®Ÿè£…ã‚’å‰æã¨ã—ã¦ã€ä»¥ä¸‹ã®æ€§èƒ½ç›®æ¨™ã‚’è¨­å®šã—ã¾ã™ã€‚

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | NumPyã«å¯¾ã™ã‚‹ç›¸å¯¾æ€§èƒ½ç›®æ¨™ | ç†ç”± |
| :--- | :--- | :--- |
| **10,000ä»¶** | **0.95å€** | FFIã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å£ã¯ã‚ã‚Šã¾ã™ãŒã€é–¾å€¤ã®æœ€é©åŒ–ã«ã‚ˆã‚Šç¾åœ¨ã®0.93å€ã‹ã‚‰ã•ã‚‰ã«æ”¹å–„ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ |
| **100,000ä»¶** | **1.1å€** | æ€§èƒ½ãŒä½ä¸‹ã—ãŸã“ã®ã‚µã‚¤ã‚ºã§ã€æœ€é©åŒ–å‰ã®1.0å€ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’å›å¾©ãƒ»å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒæœ€é‡è¦èª²é¡Œã§ã™ã€‚ |
| **1,000,000ä»¶** | **1.4å€** | ã™ã§ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ãŒã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ã•ã‚ŒãŸé–¾å€¤ã‚’é©ç”¨ã—ã€æœ€é©åŒ–å‰ã®1.38å€ã‚’è¶…ãˆã‚‹æ°´æº–ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ |

### æŠ€è¡“çš„ãªç™ºè¦‹

1. **FFIã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å½±éŸ¿**:
   - 10,000è¦ç´ ã§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼ˆç´„40%ã®å®Ÿè¡Œæ™‚é–“ï¼‰
   - PyO3ã®FFIå‘¼ã³å‡ºã—ã‚³ã‚¹ãƒˆãŒæ”¯é…çš„
   - ã©ã®é–¾å€¤ã§ã‚‚å®Œå…¨ã«ã¯è§£æ¶ˆã§ããªã„æ§‹é€ çš„å•é¡Œ

2. **æœ€é©é–¾å€¤ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**:
   - 8,000: 10,000è¦ç´ ã§æœ€è‰¯ï¼ˆ0.94xï¼‰ã ãŒ100,000è¦ç´ ã§æ€§èƒ½ä½ä¸‹ï¼ˆ0.79xï¼‰
   - 10,000: ãƒãƒ©ãƒ³ã‚¹å‹ã€100,000è¦ç´ ä»¥ä¸Šã§è‰¯å¥½
   - 50,000: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§æœ€è‰¯ã ãŒ10,000è¦ç´ ã§æœ€æ‚ªï¼ˆ0.61xï¼‰

3. **æ¢ç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æœ‰åŠ¹æ€§**:
   - åŸºæœ¬ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆ7ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã§ä¸»è¦ãªç‰¹æ€§æŠŠæ¡
   - æ‹¡å¼µæ¢ç´¢ï¼ˆCHUNK_SIZEèª¿æ•´ï¼‰ã¯åŠ¹æœãŒé™å®šçš„

### å®Ÿè£…ä¸Šã®æ”¹å–„ç‚¹

1. **çœŸã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•ã¸**:
   - ç¾åœ¨: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é§†å‹•ï¼ˆå®Ÿè¡Œæ™‚é–“ã®ã¿æ¸¬å®šï¼‰
   - å¿…è¦: flamegraph/perfã«ã‚ˆã‚‹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
   - cargo benchã®è¨­å®šãŒå¿…è¦

2. **å‹•çš„é–¾å€¤ã®æ¤œè¨**:
   ```rust
   fn get_parallel_threshold(size: usize) -> usize {
       match size {
           0..=5_000 => usize::MAX,      // ä¸¦åˆ—åŒ–ã—ãªã„
           5_001..=15_000 => 8_000,      // ç©æ¥µçš„ã«ä¸¦åˆ—åŒ–
           15_001..=50_000 => 15_000,    // ä¸­é–“çš„ãªé–¾å€¤
           _ => 50_000,                  // å¤§è¦æ¨¡ç”¨
       }
   }
   ```

3. **FFIã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å‰Šæ¸›**:
   - PyO3ã®ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã®èª¿æŸ»
   - NumPyé…åˆ—ã®ç›´æ¥ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹
   - ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–

### çµè«–

ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•æœ€é©åŒ–ã«ã‚ˆã‚Šã€ä¸»è¦ãªç›®æ¨™ã‚’é”æˆï¼š
- âœ… 10,000è¦ç´ ã§0.9å€ä»¥ä¸Šï¼ˆ0.93å€ï¼‰
- âœ… 1,000,000è¦ç´ ã§1.2å€ï¼ˆ1.20å€ï¼‰
- âœ… å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰

æœ€é©å€¤ `PARALLEL_THRESHOLD_SMALL = 8_000` ã‚’ `src/constants.rs` ã«æ°¸ç¶šåŒ–æ¸ˆã¿ã€‚