# Migration Guide: QuantForge v0.1.0 - Apache Arrow Native API

## Overview

QuantForge v0.1.0 introduces a new Apache Arrow Native API that provides better integration with modern data processing pipelines. This guide will help you migrate from the NumPy-based API to the new Arrow-first API.

## Key Changes

### 1. New Arrow-First API

The primary API now uses PyArrow arrays for better performance and zero-copy operations where possible.

```python
# New: Arrow API (recommended)
import pyarrow as pa
import quantforge.arrow_api as qf

spots = pa.array([100.0, 105.0, 110.0])
strikes = pa.array([100.0, 100.0, 100.0])
times = pa.array([1.0, 1.0, 1.0])
rates = pa.array([0.05, 0.05, 0.05])
sigmas = pa.array([0.2, 0.2, 0.2])

prices = qf.call_price(spots, strikes, times, rates, sigmas)
```

### 2. NumPy Compatibility Layer

For existing code, a NumPy compatibility layer is provided:

```python
# NumPy compatibility (for migration)
from quantforge.numpy_compat import call_price_numpy

# Works with NumPy arrays
import numpy as np
spots = np.array([100.0, 105.0, 110.0])
prices = call_price_numpy(spots, strikes, times, rates, sigmas)
```

### 3. Existing API Still Works

The original API continues to work unchanged:

```python
# Original API (still supported)
from quantforge import black_scholes

prices = black_scholes.call_price_batch(spots, strikes, times, rates, sigmas)
```

## Migration Strategy

### Step 1: Assess Your Current Usage

Identify which API you're currently using:

- **Direct NumPy arrays**: Continue using existing API or migrate to `numpy_compat`
- **Working with PyArrow/Parquet**: Migrate to Arrow API for better performance
- **Mixed workflows**: Consider gradual migration using compatibility layer

### Step 2: Choose Your Migration Path

#### Option A: Minimal Changes (NumPy Compat)

If you want minimal code changes:

```python
# Before
from quantforge import black_scholes
prices = black_scholes.call_price_batch(spots, strikes, times, rates, sigmas)

# After
from quantforge.numpy_compat import call_price_numpy
prices = call_price_numpy(spots, strikes, times, rates, sigmas)
```

#### Option B: Full Arrow Migration (Recommended)

For best performance and future compatibility:

```python
# Before
import numpy as np
from quantforge import black_scholes

spots = np.array([100.0, 105.0, 110.0])
prices = black_scholes.call_price_batch(spots, strikes, times, rates, sigmas)

# After
import pyarrow as pa
import quantforge.arrow_api as qf

spots = pa.array([100.0, 105.0, 110.0])
prices = qf.call_price(spots, strikes, times, rates, sigmas)
# Convert back to NumPy if needed
prices_np = prices.to_numpy()
```

### Step 3: Update Your Dependencies

Add PyArrow to your requirements:

```bash
pip install pyarrow>=14.0.0
```

Or in your `pyproject.toml`:

```toml
dependencies = [
    "quantforge>=0.1.0",
    "pyarrow>=14.0.0",
]
```

## API Comparison

### Function Mapping

| Old API | NumPy Compat | Arrow API |
|---------|--------------|-----------|
| `black_scholes.call_price_batch()` | `call_price_numpy()` | `arrow_api.call_price()` |
| `black_scholes.put_price_batch()` | `put_price_numpy()` | `arrow_api.put_price()` |
| `black_scholes.greeks_batch()` | `greeks_numpy()` | `arrow_api.greeks()` |
| `black_scholes.implied_volatility_batch()` | `implied_volatility_numpy()` | `arrow_api.implied_volatility()` |

### Parameter Changes

All functions maintain the same parameter names and order:
- `spots` (or `s` for scalar functions)
- `strikes` (or `k`)
- `times` (or `t`)
- `rates` (or `r`)
- `sigmas` (or `sigma`)

### Return Type Changes

| API | Return Type |
|-----|-------------|
| Original | `numpy.ndarray` |
| NumPy Compat | `numpy.ndarray` |
| Arrow API | `pyarrow.Array` |

## Performance Considerations

### When to Use Each API

1. **Arrow API**: Best for
   - Large datasets (>10,000 elements)
   - Integration with Arrow/Parquet workflows
   - Minimal memory copying requirements

2. **NumPy Compat**: Best for
   - Existing NumPy-based code
   - Small to medium datasets
   - Quick migration without major refactoring

3. **Original API**: Continue using for
   - Legacy code that's working well
   - When you need specific batch functions

### Performance Benchmarks

| Data Size | NumPy API | Arrow API | Speedup |
|-----------|-----------|-----------|---------|
| 100 | 6.77 μs | 13.76 μs | 0.49x |
| 1,000 | 41.03 μs | 45.81 μs | 0.90x |
| 10,000 | 293.77 μs | 288.88 μs | 1.02x |
| 100,000 | 1,520 μs | 1,445 μs | 1.05x |
| 1,000,000 | 14,200 μs | 14,241 μs | 1.00x |

*Note: Arrow API performance improves with larger datasets*

## Broadcasting Support

The Arrow API supports automatic broadcasting for scalar values:

```python
import pyarrow as pa
import quantforge.arrow_api as qf

# Mix of scalars and arrays
spots = pa.array([100.0, 105.0, 110.0])
strikes = pa.array([100.0])  # Will be broadcast
times = pa.array([1.0])      # Will be broadcast
rates = pa.array([0.05])     # Will be broadcast
sigmas = pa.array([0.2, 0.25, 0.3])

# Automatic broadcasting
broadcasted = qf.broadcast_arrays(spots, strikes, times, rates, sigmas)
prices = qf.call_price(*broadcasted)
```

## Common Migration Issues

### Issue 1: Import Errors

```python
# Error: ModuleNotFoundError: No module named 'pyarrow'
# Solution: Install PyArrow
pip install pyarrow
```

### Issue 2: Type Mismatches

```python
# Error: TypeError: Expected pyarrow.Array
# Solution: Convert to Arrow array
spots = pa.array(numpy_array)
```

### Issue 3: Return Type Handling

```python
# If you need NumPy array from Arrow API
arrow_result = qf.call_price(...)
numpy_result = arrow_result.to_numpy()
```

## Example: Complete Migration

### Before (NumPy-based)

```python
import numpy as np
from quantforge import black_scholes

def calculate_portfolio_values(positions):
    """Calculate option values for portfolio positions."""
    spots = np.array([p['spot'] for p in positions])
    strikes = np.array([p['strike'] for p in positions])
    times = np.array([p['time'] for p in positions])
    rates = np.array([p['rate'] for p in positions])
    sigmas = np.array([p['sigma'] for p in positions])
    
    prices = black_scholes.call_price_batch(
        spots, strikes, times, rates, sigmas
    )
    
    greeks = black_scholes.greeks_batch(
        spots, strikes, times, rates, sigmas
    )
    
    return {
        'prices': prices,
        'deltas': greeks['delta'],
        'gammas': greeks['gamma'],
    }
```

### After (Arrow-based)

```python
import pyarrow as pa
import quantforge.arrow_api as qf

def calculate_portfolio_values(positions):
    """Calculate option values for portfolio positions."""
    spots = pa.array([p['spot'] for p in positions])
    strikes = pa.array([p['strike'] for p in positions])
    times = pa.array([p['time'] for p in positions])
    rates = pa.array([p['rate'] for p in positions])
    sigmas = pa.array([p['sigma'] for p in positions])
    
    prices = qf.call_price(
        spots, strikes, times, rates, sigmas
    )
    
    greeks = qf.greeks(
        spots, strikes, times, rates, sigmas
    )
    
    return {
        'prices': prices.to_numpy(),  # Convert if needed
        'deltas': greeks['delta'].to_numpy(),
        'gammas': greeks['gamma'].to_numpy(),
    }
```

## Deprecation Notice

The following functions are deprecated and will be removed in v0.2.0:
- `numpy_compat.black_scholes_call()` → Use `call_price_numpy()`
- `numpy_compat.black_scholes_put()` → Use `put_price_numpy()`

## Getting Help

If you encounter issues during migration:

1. Check the [API documentation](../api/index.md)
2. Review the [examples](../examples/)
3. Report issues on [GitHub](https://github.com/quantforge/quantforge/issues)

## Summary

The new Arrow Native API provides:
- Better integration with modern data pipelines
- Improved performance for large datasets
- Zero-copy operations where possible
- Backward compatibility through NumPy compat layer

Migration is optional but recommended for new projects and those working with Arrow/Parquet data.