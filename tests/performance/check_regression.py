#!/usr/bin/env python3
"""ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡Œæ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ.

GitHub Actionsã®CIç’°å¢ƒã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æœ€æ–°çµæœã‚’æ¯”è¼ƒã—ã€
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡ŒãŒã‚ã‚‹å ´åˆã¯ãƒ“ãƒ«ãƒ‰ã‚’å¤±æ•—ã•ã›ã¾ã™ã€‚
"""

import json
import re
import sys
from pathlib import Path
from typing import Dict, List


class RegressionChecker:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡Œã‚’ãƒã‚§ãƒƒã‚¯."""
    
    def __init__(self, threshold: float = 1.2):
        """åˆæœŸåŒ–.
        
        Args:
            threshold: è¨±å®¹ã™ã‚‹åŠ£åŒ–ç‡ï¼ˆ1.2 = 20%ã®åŠ£åŒ–ã¾ã§è¨±å®¹ï¼‰
        """
        self.threshold = threshold
        self.violations: List[str] = []
        self.warnings: List[str] = []
        
    def load_json(self, path: Path) -> Dict:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€."""
        if not path.exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
            sys.exit(1)
            
        with open(path) as f:
            return json.load(f)
    
    def extract_benchmark_times(self, benchmarks: List[Dict]) -> Dict[str, Dict[str, float]]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‹ã‚‰å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡ºï¼ˆgenerate_benchmark_report.pyã¨åŒã˜å½¢å¼ï¼‰."""
        results: Dict[str, Dict[str, float]] = {}
        
        for bench in benchmarks:
            name = bench["name"]
            mean_time = bench["stats"].get("mean", 0)
            
            # ãƒ†ã‚¹ãƒˆåã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º
            if "test_quantforge_single" in name:
                results.setdefault("single", {})["quantforge"] = mean_time
            elif "test_pure_python_single" in name:
                results.setdefault("single", {})["pure_python"] = mean_time
            elif "test_numpy_scipy_single" in name:
                results.setdefault("single", {})["numpy_scipy"] = mean_time
            elif "test_quantforge_batch" in name:
                size = self._extract_size(name)
                key = f"batch_{size}"
                results.setdefault(key, {})["quantforge"] = mean_time
            elif "test_pure_python_batch" in name:
                size = self._extract_size(name)
                key = f"batch_{size}"
                results.setdefault(key, {})["pure_python"] = mean_time
            elif "test_numpy_scipy_batch" in name:
                size = self._extract_size(name)
                key = f"batch_{size}"
                results.setdefault(key, {})["numpy_scipy"] = mean_time
        
        return results
    
    def _extract_size(self, name: str) -> int:
        """ãƒ†ã‚¹ãƒˆåã‹ã‚‰ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŠ½å‡º."""
        match = re.search(r"\[(\d+)\]", name)
        if match:
            return int(match.group(1))
        return 0
    
    def format_time(self, time_seconds: float) -> str:
        """æ™‚é–“ã‚’é©åˆ‡ãªå˜ä½ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ."""
        if time_seconds < 1e-6:
            return f"{time_seconds * 1e9:.2f} ns"
        elif time_seconds < 1e-3:
            return f"{time_seconds * 1e6:.2f} Î¼s"
        elif time_seconds < 1:
            return f"{time_seconds * 1e3:.2f} ms"
        else:
            return f"{time_seconds:.2f} s"
    
    def compare_metrics(self, baseline_times: Dict, latest_times: Dict) -> None:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ¯”è¼ƒã—ã¦é€€è¡Œã‚’æ¤œå‡º."""
        # å˜ä¸€è¨ˆç®—ã®æ¯”è¼ƒ
        if "single" in baseline_times and "single" in latest_times:
            for impl in ["quantforge", "pure_python", "numpy_scipy"]:
                if impl in baseline_times["single"] and impl in latest_times["single"]:
                    base_time = baseline_times["single"][impl]
                    latest_time = latest_times["single"][impl]
                    
                    if latest_time > base_time * self.threshold:
                        ratio = latest_time / base_time
                        self.violations.append(
                            f"å˜ä¸€è¨ˆç®— ({impl}): {self.format_time(base_time)} â†’ "
                            f"{self.format_time(latest_time)} ({ratio:.2f}x slower)"
                        )
                    elif latest_time > base_time * 1.1:  # 10%ã®åŠ£åŒ–ã¯è­¦å‘Š
                        ratio = latest_time / base_time
                        self.warnings.append(
                            f"å˜ä¸€è¨ˆç®— ({impl}): {self.format_time(base_time)} â†’ "
                            f"{self.format_time(latest_time)} ({ratio:.2f}x slower)"
                        )
        
        # ãƒãƒƒãƒå‡¦ç†ã®æ¯”è¼ƒ
        for key in baseline_times:
            if key.startswith("batch_") and key in latest_times:
                for impl in ["quantforge", "pure_python", "numpy_scipy"]:
                    if impl in baseline_times[key] and impl in latest_times[key]:
                        base_time = baseline_times[key][impl]
                        latest_time = latest_times[key][impl]
                        size = key.replace("batch_", "")
                        
                        if latest_time > base_time * self.threshold:
                            ratio = latest_time / base_time
                            self.violations.append(
                                f"ãƒãƒƒãƒå‡¦ç† {size}ä»¶ ({impl}): {self.format_time(base_time)} â†’ "
                                f"{self.format_time(latest_time)} ({ratio:.2f}x slower)"
                            )
                        elif latest_time > base_time * 1.1:  # 10%ã®åŠ£åŒ–ã¯è­¦å‘Š
                            ratio = latest_time / base_time
                            self.warnings.append(
                                f"ãƒãƒƒãƒå‡¦ç† {size}ä»¶ ({impl}): {self.format_time(base_time)} â†’ "
                                f"{self.format_time(latest_time)} ({ratio:.2f}x slower)"
                            )
    
    def check_regression(self, baseline_path: Path, latest_path: Path) -> bool:
        """é€€è¡Œãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ.
        
        Returns:
            True: é€€è¡Œãªã—ã€False: é€€è¡Œæ¤œå‡º
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        baseline = self.load_json(baseline_path)
        latest = self.load_json(latest_path)
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’æŠ½å‡º
        baseline_times = self.extract_benchmark_times(baseline.get("benchmarks", []))
        latest_times = self.extract_benchmark_times(latest.get("benchmarks", []))
        
        # æ¯”è¼ƒ
        self.compare_metrics(baseline_times, latest_times)
        
        # çµæœã‚’å‡ºåŠ›
        print("=" * 60)
        print("ğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡Œãƒã‚§ãƒƒã‚¯")
        print("=" * 60)
        
        if self.warnings:
            print("\nâš ï¸ è­¦å‘Šï¼ˆ10%ä»¥ä¸Šã®åŠ£åŒ–ï¼‰:")
            for warning in self.warnings:
                print(f"  - {warning}")
        
        if self.violations:
            print("\nâŒ é€€è¡Œæ¤œå‡ºï¼ˆ20%ä»¥ä¸Šã®åŠ£åŒ–ï¼‰:")
            for violation in self.violations:
                print(f"  - {violation}")
            print("\né€€è¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False
        
        if not self.warnings and not self.violations:
            print("\nâœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡Œãªã—")
        
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†."""
    import argparse
    
    parser = argparse.ArgumentParser(description="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€€è¡Œæ¤œå‡º")
    parser.add_argument(
        "--baseline",
        type=Path,
        default=Path("tests/performance/baseline.json"),
        help="ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--latest", 
        type=Path,
        default=Path("benchmark_results/latest.json"),
        help="æœ€æ–°çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=1.2,
        help="è¨±å®¹ã™ã‚‹åŠ£åŒ–ç‡ï¼ˆ1.2 = 20%%ã®åŠ£åŒ–ã¾ã§è¨±å®¹ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è­¦å‘Šã®ã¿
    if not args.baseline.exists():
        print("âš ï¸ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        print("  åˆå›å®Ÿè¡Œæ™‚ã¯ update_baseline.py ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        sys.exit(0)
    
    checker = RegressionChecker(threshold=args.threshold)
    success = checker.check_regression(args.baseline, args.latest)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()